{"1":{"id":"1","parent":"#","text":"Test","icon":"","li_attr":{},"a_attr":{},"type":"code","script":"ls\nls -l\n#sudo apt update\n\na={{c.aaaa}}\necho $a done\n\necho \"Please enter your input\"\nread -s INPUT\necho input: $INPUT\n","sort":4,"description":{"ops":[{"insert":"this is a "},{"attributes":{"bold":true},"insert":"test ..."},{"insert":"\n"}]},"found":true,"variables":{"hhhb":{"private":false,"ask":false,"type":"Text","value":"kkkb","idn":"0"},"aaaa":{"private":false,"ask":true,"type":"Text","value":"bbbbhh","idn":"1"}}},"8f115abd-a0f1-4bd0-951e-d36d69229f31":{"text":"Test 2","parent":"1","script":"\n\necho \"jump:{{c.jumpTo}}\"\n\nsql=\"select json_agg(users.* ORDER BY created_at DESC) AS all from (select * from users ORDER BY created_at DESC limit 20) users \"\nresults=$(sudo su postgres -c \"psql rac -q -c '$sql' -A -t | python -m json.tool \")\necho \"var:json:$results\"\n\nhostname\nexit\nhostname\n\n","id":"8f115abd-a0f1-4bd0-951e-d36d69229f31","type":"code","description":{"ops":[{"attributes":{"color":"#dcdcaa"},"insert":"$"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\"#console\""},{"insert":")."},{"attributes":{"color":"#dcdcaa"},"insert":"append"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\" \""},{"insert":") Test 2\n"}]},"sort":0,"variables":{"jumpTo":{"private":false,"ask":false,"type":"Text","value":"rac-portal.cybera.ca","idn":"0"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Registered users","idn":"1"},"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"2"},"icon":{"private":false,"ask":false,"type":"Text","value":"database","idn":"3"}},"found":true,"hist":[{"ds":"2023-12-22T17:19:26.733Z","event":"save","userName":"scott"},{"ds":"2023-12-22T17:29:20.890Z","event":"save","userName":"scott"},{"ds":"2023-12-22T17:45:26.435Z","event":"save","userName":"scott"},{"ds":"2024-01-06T22:58:06.009Z","event":"save","userName":"scott"},{"ds":"2024-01-08T03:19:14.604Z","event":"save","userName":"scott"},{"ds":"2024-01-08T03:25:06.695Z","event":"save","userName":"scott"},{"ds":"2024-01-08T03:28:28.818Z","event":"save","userName":"scott"},{"ds":"2024-01-08T03:35:37.617Z","event":"save","userName":"scott"},{"ds":"2024-01-08T03:45:54.062Z","event":"save","userName":"scott"},{"ds":"2024-01-08T03:48:43.667Z","event":"save","userName":"scott"},{"ds":"2024-01-08T03:51:14.760Z","event":"save","userName":"scott"},{"ds":"2024-01-08T03:57:11.447Z","event":"save","userName":"scott"},{"ds":"2024-01-08T04:02:14.689Z","event":"save","userName":"scott"},{"ds":"2024-01-08T04:14:07.018Z","event":"save","userName":"scott"},{"ds":"2024-01-08T04:18:34.567Z","event":"save","userName":"scott"},{"ds":"2024-01-08T04:22:23.892Z","event":"save","userName":"scott"},{"ds":"2024-01-08T16:55:51.802Z","event":"save","userName":"scott"},{"ds":"2024-01-08T17:08:54.811Z","event":"save","userName":"scott"},{"ds":"2024-01-08T17:13:19.827Z","event":"save","userName":"scott"},{"ds":"2024-01-08T17:13:59.646Z","event":"save","userName":"scott"},{"ds":"2024-01-08T17:15:34.797Z","event":"save","userName":"scott"},{"ds":"2024-01-08T17:16:45.526Z","event":"save","userName":"scott"},{"ds":"2024-01-08T17:24:20.416Z","event":"save","userName":"scott"},{"ds":"2024-01-08T17:26:36.433Z","event":"save","userName":"scott"},{"ds":"2024-01-08T17:32:00.757Z","event":"save","userName":"scott"},{"ds":"2024-01-08T17:35:34.159Z","event":"save","userName":"scott"},{"ds":"2024-01-08T17:44:32.837Z","event":"save","userName":"scott"},{"ds":"2024-01-08T18:52:57.342Z","event":"save","userName":"scott"},{"ds":"2024-01-08T19:00:26.932Z","event":"save","userName":"scott"},{"ds":"2024-01-08T19:01:30.249Z","event":"save","userName":"scott"},{"ds":"2024-01-08T20:24:01.014Z","event":"save","userName":"scott"},{"ds":"2024-01-08T20:25:11.545Z","event":"save","userName":"scott"},{"ds":"2024-01-08T20:30:37.723Z","event":"save","userName":"scott"},{"ds":"2024-01-08T20:31:41.089Z","event":"save","userName":"scott"},{"ds":"2024-01-08T20:42:23.654Z","event":"save","userName":"scott"},{"ds":"2024-01-08T21:48:06.834Z","event":"save","userName":"scott"},{"ds":"2024-01-08T21:50:34.004Z","event":"save","userName":"scott"},{"ds":"2024-01-08T22:24:15.546Z","event":"save","userName":"scott"},{"ds":"2024-01-08T22:25:45.438Z","event":"save","userName":"scott"},{"ds":"2024-01-08T22:26:52.035Z","event":"save","userName":"scott"},{"ds":"2024-01-08T22:28:06.467Z","event":"save","userName":"scott"}],"backups":[{"ds":"2024-01-08T22:28:06.468Z","data":{"text":"Test 2","description":{"ops":[{"attributes":{"color":"#dcdcaa"},"insert":"$"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\"#console\""},{"insert":")."},{"attributes":{"color":"#dcdcaa"},"insert":"append"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\" \""},{"insert":") Test 2\n"}]},"script":"\n\necho \"jump:{{c.jumpTo}}\"\n\nsql=\"select json_agg(users.* ORDER BY created_at DESC) AS all from (select * from users ORDER BY created_at DESC limit 20) users \"\nresults=$(sudo su postgres -c \"psql rac -q -c '$sql' -A -t | python -m json.tool \")\necho \"var:json:$results\"\n\nhostname\nexit\nhostname\n\n","variables":{"jumpTo":{"private":false,"ask":false,"type":"Text","value":"rac-portal.cybera.ca","idn":"0"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Registered users","idn":"1"},"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"2"},"icon":{"private":false,"ask":false,"type":"Text","value":"database","idn":"3"}}}},{"ds":"2024-01-08T22:26:52.035Z","data":{"text":"Test 2","description":{"ops":[{"attributes":{"color":"#dcdcaa"},"insert":"$"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\"#console\""},{"insert":")."},{"attributes":{"color":"#dcdcaa"},"insert":"append"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\" \""},{"insert":") Test 2\n"}]},"script":"\n\necho \"jump:{{c.jumpTo}}\"\n\nsql=\"select json_agg(users.* ORDER BY created_at DESC) AS all from (select * from users ORDER BY created_at DESC limit 3) users \"\nresults=$(sudo su postgres -c \"psql rac -q -c '$sql' -A -t | python -m json.tool \")\necho \"var:json:$results\"\n\nhostname\nexit\nhostname\n\n","variables":{"jumpTo":{"private":false,"ask":false,"type":"Text","value":"rac-portal.cybera.ca","idn":"0"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Registered users","idn":"1"},"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"2"},"icon":{"private":false,"ask":false,"type":"Text","value":"database","idn":"3"}}}},{"ds":"2024-01-08T22:25:45.438Z","data":{"text":"Test 2","description":{"ops":[{"attributes":{"color":"#dcdcaa"},"insert":"$"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\"#console\""},{"insert":")."},{"attributes":{"color":"#dcdcaa"},"insert":"append"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\" \""},{"insert":") Test 2\n"}]},"script":"\n\necho \"jump:{{c.jumpTo}}\"\n\nsql=\"select json_agg(users.* ORDER BY created_at DESC) AS all from (select * from users ORDER BY created_at DESC limit 3) t \"\nresults=$(sudo su postgres -c \"psql rac -q -c '$sql' -A -t | python -m json.tool \")\necho \"var:json:$results\"\n\nhostname\nexit\nhostname\n\n","variables":{"jumpTo":{"private":false,"ask":false,"type":"Text","value":"rac-portal.cybera.ca","idn":"0"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Registered users","idn":"1"},"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"2"},"icon":{"private":false,"ask":false,"type":"Text","value":"database","idn":"3"}}}},{"ds":"2024-01-08T22:24:15.546Z","data":{"text":"Test 2","description":{"ops":[{"attributes":{"color":"#dcdcaa"},"insert":"$"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\"#console\""},{"insert":")."},{"attributes":{"color":"#dcdcaa"},"insert":"append"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\" \""},{"insert":") Test 2\n"}]},"script":"\n\necho \"jump:{{c.jumpTo}}\"\n\nsql=\"select json_agg(users.* ORDER BY created_at DESC) AS all from (select * from users ORDER BY created_at DESC limit 3)  \"\nresults=$(sudo su postgres -c \"psql rac -q -c '$sql' -A -t | python -m json.tool \")\necho \"var:json:$results\"\n\nhostname\nexit\nhostname\n\n","variables":{"jumpTo":{"private":false,"ask":false,"type":"Text","value":"rac-portal.cybera.ca","idn":"0"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Registered users","idn":"1"},"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"2"},"icon":{"private":false,"ask":false,"type":"Text","value":"database","idn":"3"}}}},{"ds":"2024-01-08T21:50:34.004Z","data":{"text":"Test 2","description":{"ops":[{"attributes":{"color":"#dcdcaa"},"insert":"$"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\"#console\""},{"insert":")."},{"attributes":{"color":"#dcdcaa"},"insert":"append"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\" \""},{"insert":") Test 2\n"}]},"script":"\n\necho \"jump:{{c.jumpTo}}\"\n\nsql=\"select json_agg(users.* ORDER BY created_at DESC) AS all from users  \"\nresults=$(sudo su postgres -c \"psql rac -q -c '$sql' -A -t | python -m json.tool \")\necho \"var:json:$results\"\n\nhostname\nexit\nhostname\n\n","variables":{"jumpTo":{"private":false,"ask":false,"type":"Text","value":"rac-portal.cybera.ca","idn":"0"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Registered users","idn":"1"},"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"2"},"icon":{"private":false,"ask":false,"type":"Text","value":"database","idn":"3"}}}},{"ds":"2024-01-08T21:48:06.834Z","data":{"text":"Test 2","description":{"ops":[{"attributes":{"color":"#dcdcaa"},"insert":"$"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\"#console\""},{"insert":")."},{"attributes":{"color":"#dcdcaa"},"insert":"append"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\" \""},{"insert":") Test 2\n"}]},"script":"\n\necho \"jump:{{c.jumpTo}}\"\n\nsql=\"select json_agg(users.*) AS all from users ORDER BY created_at DESC \"\nresults=$(sudo su postgres -c \"psql rac -q -c '$sql' -A -t | python -m json.tool \")\necho \"var:json:$results\"\n\nhostname\nexit\nhostname\n\n","variables":{"jumpTo":{"private":false,"ask":false,"type":"Text","value":"rac-portal.cybera.ca","idn":"0"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Registered users","idn":"1"},"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"2"},"icon":{"private":false,"ask":false,"type":"Text","value":"database","idn":"3"}}}},{"ds":"2024-01-08T20:42:23.654Z","data":{"text":"Test 2","description":{"ops":[{"attributes":{"color":"#dcdcaa"},"insert":"$"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\"#console\""},{"insert":")."},{"attributes":{"color":"#dcdcaa"},"insert":"append"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\" \""},{"insert":") Test 2\n"}]},"script":"\n\necho \"jump:{{c.jumpTo}}\"\n\nsql=\"select json_agg(users.*) AS all from users \"\nresults=$(sudo su postgres -c \"psql rac -q -c '$sql' -A -t | python -m json.tool \")\necho \"var:json:$results\"\n\nhostname\nexit\nhostname\n\n","variables":{"jumpTo":{"private":false,"ask":false,"type":"Text","value":"rac-portal.cybera.ca","idn":"0"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Registered users","idn":"1"},"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"2"},"icon":{"private":false,"ask":false,"type":"Text","value":"database"}}}},{"ds":"2024-01-08T20:31:41.089Z","data":{"text":"Test 2","description":{"ops":[{"attributes":{"color":"#dcdcaa"},"insert":"$"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\"#console\""},{"insert":")."},{"attributes":{"color":"#dcdcaa"},"insert":"append"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\" \""},{"insert":") Test 2\n"}]},"script":"\n\necho \"jump:{{c.jumpTo}}\"\n\nsql=\"select json_agg(users.*) AS all from users \"\nresults=$(sudo su postgres -c \"psql rac -q -c '$sql' -A -t | python -m json.tool \")\necho \"var:json:$results\"\n\nhostname\nexit\nhostname\n\n","variables":{"jumpTo":{"private":false,"ask":false,"type":"Text","value":"rac-portal.cybera.ca","idn":"0"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Registered users","idn":"1"},"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"3"},"icon":{"private":false,"ask":false,"type":"Text","value":"users"}}}},{"ds":"2024-01-08T20:30:37.723Z","data":{"text":"Test 2","description":{"ops":[{"attributes":{"color":"#dcdcaa"},"insert":"$"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\"#console\""},{"insert":")."},{"attributes":{"color":"#dcdcaa"},"insert":"append"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\" \""},{"insert":") Test 2\n"}]},"script":"\n\necho \"jump:{{c.jumpTo}}\"\n\nsql=\"select json_agg(users.*) AS all from users \"\nresults=$(sudo su postgres -c \"psql rac -q -c '$sql' -A -t | python -m json.tool \")\necho \"var:json:$results\"\n\nhostname\nexit\nhostname\n\n","variables":{"jumpTo":{"private":false,"ask":false,"type":"Text","value":"rac-portal.cybera.ca","idn":"0"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Registered users"},"icon":{"private":false,"ask":false,"type":"Text","value":"cross"},"promoted":{"private":false,"ask":false,"type":"Text","value":"true"}}}},{"ds":"2024-01-08T20:25:11.546Z","data":{"text":"Test 2","description":{"ops":[{"attributes":{"color":"#dcdcaa"},"insert":"$"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\"#console\""},{"insert":")."},{"attributes":{"color":"#dcdcaa"},"insert":"append"},{"insert":"("},{"attributes":{"color":"#ce9178"},"insert":"\" \""},{"insert":") Test 2\n"}]},"script":"\n\necho \"jump:{{c.jumpTo}}\"\n\nsql=\"select json_agg(users.*) AS all from users \"\nresults=$(sudo su postgres -c \"psql rac -q -c '$sql' -A -t | python -m json.tool \")\necho \"var:json:$results\"\n\nhostname\nexit\nhostname\n\n","variables":{"jumpTo":{"private":false,"ask":false,"type":"Text","value":"rac-portal.cybera.ca"}}}}]},"6f4987e7-6eaa-495b-be96-964645c23612":{"text":"Containers","parent":"#","script":"","description":{"ops":[{"attributes":{"link":"https://en.wikipedia.org/wiki/Containerization_(computing)"},"insert":"https://en.wikipedia.org/wiki/Containerization_(computing)"},{"insert":"\n\nIn software engineering, containerization is operating system-level virtualization or application-level virtualization over multiple network resources so that software applications can run in isolated user spaces called containers in any cloud or non-cloud environment, regardless of type or vendor.\n"}]},"id":"6f4987e7-6eaa-495b-be96-964645c23612","type":"code","sort":1,"variables":{}},"0eeabd9e-1b19-41b5-bbc2-327a95461f81":{"text":"Docker","parent":"6f4987e7-6eaa-495b-be96-964645c23612","script":"","description":{"ops":[{"attributes":{"link":"https://en.wikipedia.org/wiki/Docker_(software)"},"insert":"https://en.wikipedia.org/wiki/Docker_(software)"},{"insert":"\n\n"},{"attributes":{"bold":true},"insert":"Docker"},{"insert":" is a set of "},{"attributes":{"color":"#3366cc","link":"https://en.wikipedia.org/wiki/Platform_as_a_service"},"insert":"platform as a service"},{"insert":" (PaaS) products that use "},{"attributes":{"color":"#3366cc","link":"https://en.wikipedia.org/wiki/OS-level_virtualization"},"insert":"OS-level virtualization"},{"insert":" to deliver software in packages called "},{"attributes":{"italic":true,"color":"#3366cc","link":"https://en.wikipedia.org/wiki/Container_(virtualization)"},"insert":"containers"},{"insert":". The service has both free and premium tiers. The software that hosts the containers is called "},{"attributes":{"bold":true},"insert":"Docker Engine"},{"insert":". It was first released in 2013 and is developed by "},{"attributes":{"color":"#3366cc","link":"https://en.wikipedia.org/wiki/Docker,_Inc."},"insert":"Docker, Inc."},{"insert":"\nDocker is a tool that is used to automate the deployment of applications in lightweight containers so that applications can work efficiently in different environments in isolation.\n\n"},{"insert":{"image":"https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Docker-linux-interfaces.svg/220px-Docker-linux-interfaces.svg.png"}},{"insert":"\nDocker can use different interfaces to access virtualization features of the Linux kernel.\n\n"},{"attributes":{"link":"https://dockerlabs.collabnix.com/docker/cheatsheet/#basic-docker-clis"},"insert":"https://dockerlabs.collabnix.com/docker/cheatsheet/#basic-docker-clis"},{"insert":"\n\n\n\n\n"}]},"id":"0eeabd9e-1b19-41b5-bbc2-327a95461f81","type":"code","found":true,"variables":{}},"ff6eb569-815f-4ea3-a6d9-a29801b13f1a":{"text":"Install Docker","parent":"0eeabd9e-1b19-41b5-bbc2-327a95461f81","script":"sudo apt-get update\n\nsudo apt-get install ca-certificates curl gnupg lsb-release\n\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n\necho  \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n\nsudo apt-get update\n\nsudo apt-get -y install docker-ce docker-ce-cli containerd.io","description":{"ops":[{"insert":"Install Docker on Ubuntu 20.04 LTS\n"}]},"id":"ff6eb569-815f-4ea3-a6d9-a29801b13f1a","type":"code","variables":{},"found":true,"sort":0},"b1e874e9-a642-4920-8624-355118328fb1":{"text":"Utilities","parent":"#","script":"","description":{"ops":[{"insert":"\n"}]},"id":"b1e874e9-a642-4920-8624-355118328fb1","type":"code","sort":3},"96dfb760-54b4-4bf8-a095-2dd7fbe84f51":{"text":"top","parent":"b1e874e9-a642-4920-8624-355118328fb1","script":"top","description":{"ops":[{"insert":"Process viewer, find the CPU-intensive programs currently running.  Hit q to stop.\n"}]},"id":"96dfb760-54b4-4bf8-a095-2dd7fbe84f51","type":"code","sort":0,"variables":{}},"73c07432-ebff-4fc1-812e-636958eb54d3":{"text":"tail syslog","parent":"b1e874e9-a642-4920-8624-355118328fb1","script":"tail -500 /var/log/syslog","description":{"ops":[{"insert":"See last 500 lines of the syslog\n\nSyslog is a protocol that computer systems use to send event data logs to a central location for storage. Logs can then be accessed by analysis and reporting software to perform audits, monitoring, troubleshooting, and other essential IT operational tasks.\n"}]},"id":"73c07432-ebff-4fc1-812e-636958eb54d3","type":"code","sort":2,"variables":{}},"00c9775a-aa1e-4f98-a839-061ba4822516":{"text":"apt update","parent":"b1e874e9-a642-4920-8624-355118328fb1","script":"sudo apt update","description":{"ops":[{"insert":"Ubuntu features a comprehensive package management system for installing, upgrading, configuring, and removing software. In addition to providing access to an organized base of over 60,000 software packages for your Ubuntu computer, the package management facilities also feature dependency resolution capabilities and software update checking.\n\nThe APT package index is essentially a database of available packages from the repositories defined in the "},{"attributes":{"color":"inherit","background":"rgba(0, 0, 0, 0.03)","code":true},"insert":"/etc/apt/sources.list"},{"insert":" file and in the "},{"attributes":{"color":"inherit","background":"rgba(0, 0, 0, 0.03)","code":true},"insert":"/etc/apt/sources.list.d"},{"insert":" directory. To update the local package index with the latest changes made in the repositories, run the following:\n"}]},"id":"00c9775a-aa1e-4f98-a839-061ba4822516","type":"code","sort":1,"found":true,"variables":{}},"ea841508-edb1-4fd7-aca1-46fbb21a97a3":{"parent":"1","text":"Test 2456kjlkhj;lkj;l","hist":[{"username":"admin","ds":"2023-09-21T20:35:33.383Z","fromId":"8f115abd-a0f1-4bd0-951e-d36d69229f31"},{"ds":"2024-01-05T18:16:18.756Z","event":"save","userName":"scott"},{"ds":"2024-01-05T18:55:51.845Z","event":"save","userName":"scott"},{"ds":"2024-01-05T19:32:08.238Z","event":"save","userName":"scott"},{"ds":"2024-01-05T20:16:24.928Z","event":"save","userName":"scott"},{"ds":"2024-01-05T20:28:30.838Z","event":"save","userName":"scott"},{"ds":"2024-01-05T20:28:32.125Z","event":"save","userName":"scott"},{"ds":"2024-01-05T20:28:33.528Z","event":"save","userName":"scott"},{"ds":"2024-01-05T20:28:34.858Z","event":"save","userName":"scott"},{"ds":"2024-01-05T20:28:36.221Z","event":"save","userName":"scott"},{"ds":"2024-01-05T20:28:37.659Z","event":"save","userName":"scott"},{"ds":"2024-01-06T00:01:19.374Z","event":"save","userName":"scott"},{"ds":"2024-01-06T00:01:27.731Z","event":"save","userName":"scott"},{"ds":"2024-01-06T00:01:46.214Z","event":"save","userName":"scott"},{"ds":"2024-01-06T00:02:35.094Z","event":"save","userName":"scott"},{"ds":"2024-01-06T00:05:24.671Z","event":"save","userName":"scott"},{"ds":"2024-01-06T17:25:56.850Z","event":"save","userName":"scott"},{"ds":"2024-01-06T17:26:13.413Z","event":"save","userName":"scott"}],"sort":1,"id":"ea841508-edb1-4fd7-aca1-46fbb21a97a3","type":"code","script":"mnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\n","description":{"ops":[{"insert":"mn,n,nkhjlkhlkhlk 2\n"}]},"variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"}},"found":true,"backup":[{"ds":"2024-01-05T18:16:18.756Z","data":{"text":"Test 2456","description":{"ops":[{"insert":"mn,n,\n"}]},"script":"","variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"}}}}],"backups":[{"ds":"2024-01-06T17:26:13.413Z","data":{"text":"Test 2456kjlkhj;lkj;l","description":{"ops":[{"insert":"mn,n,nkhjlkhlkhlk 2\n"}]},"script":"mnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\n","variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"}}}},{"ds":"2024-01-06T17:25:56.851Z","data":{"text":"Test 2456kjlkhj;lkj;l","description":{"ops":[{"insert":"mn,n,nkhjlkhlkhlk\n"}]},"script":"mnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\nmnbmnbbm\nlnlk\njkhkhk\n","variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"}}}},{"ds":"2024-01-06T00:05:24.671Z","data":{"text":"Test 2456kjlkhj;lkj;l","description":{"ops":[{"insert":"mn,n,nkhjlkhlkhlk\n"}]},"script":"mnbmnbbm\nlnlk\n","variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"},"col":{"private":false,"ask":false,"type":"Color","value":"#d62424"}}}},{"ds":"2024-01-06T00:02:35.094Z","data":{"text":"Test 2456","description":{"ops":[{"insert":"mn,n,\n"}]},"script":"mnbmnbbm\nlnlk\n","variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"}}}},{"ds":"2024-01-06T00:01:46.215Z","data":{"text":"Test 2456","description":{"ops":[{"insert":"mn,n,\n"}]},"script":"mnbmnbbm\nlnlk\n","variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"}}}},{"ds":"2024-01-06T00:01:27.731Z","data":{"text":"Test 2456","description":{"ops":[{"insert":"mn,n,\n"}]},"script":"mnbmnbbm\nlnlk\n","variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"}}}},{"ds":"2024-01-06T00:01:19.374Z","data":{"text":"Test 2456","description":{"ops":[{"insert":"mn,n,\n"}]},"script":"mnbmnbbm\nlnlk\n","variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"}}}},{"ds":"2024-01-05T20:28:37.659Z","data":{"text":"Test 2456","description":{"ops":[{"insert":"mn,n,\n"}]},"script":"mnbmnbbm\nlnlk\n","variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"}}}},{"ds":"2024-01-05T20:28:36.221Z","data":{"text":"Test 2456","description":{"ops":[{"insert":"mn,n,\n"}]},"script":"mnbmnbbm\nlnlk\n","variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"}}}},{"ds":"2024-01-05T20:28:34.858Z","data":{"text":"Test 2456","description":{"ops":[{"insert":"mn,n,\n"}]},"script":"mnbmnbbm\nlnlk\n","variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":true,"ask":false,"type":"Text","value":"mnbfb,msnbd","idn":"1"}}}}]},"032aea7f-5e3d-44a6-a6ba-5269bdf246b5":{"parent":"8f115abd-a0f1-4bd0-951e-d36d69229f31","text":"Test 2","hist":[{"username":"admin","ds":"2023-09-23T18:01:10.017Z","fromId":"ea841508-edb1-4fd7-aca1-46fbb21a97a3"},{"ds":"2023-12-27T20:17:05.680Z","event":"save","userName":"scott"}],"variables":{},"sort":0,"id":"032aea7f-5e3d-44a6-a6ba-5269bdf246b5","type":"code","script":"echo hi","description":{"ops":[{"insert":"\n"}]}},"7585d6f5-0724-414f-a31d-c921cb11990e":{"parent":"032aea7f-5e3d-44a6-a6ba-5269bdf246b5","text":"Test 22","hist":[{"username":"admin","ds":"2023-09-23T18:12:03.409Z","fromId":"ea841508-edb1-4fd7-aca1-46fbb21a97a3"}],"variables":{"test":{"private":false,"ask":false,"type":"Text","value":"bbbmn,","idn":"0"},"test2":{"private":false,"ask":false,"type":"Color","value":"#242eb2","idn":"1"}},"script":"","sort":0,"id":"7585d6f5-0724-414f-a31d-c921cb11990e","type":"code","description":{"ops":[{"insert":"\n"}]},"found":true},"c0477757-a2fa-4765-bf64-e0db8b5d3301":{"text":"Hello World Test","parent":"ff6eb569-815f-4ea3-a6d9-a29801b13f1a","script":"sudo docker run hello-world","description":{"ops":[{"insert":"This will run docker Hello World to prove install \n"}]},"id":"c0477757-a2fa-4765-bf64-e0db8b5d3301","type":"code","variables":{},"found":true},"36986302-75fc-49cc-b9dd-9db8d13a96f6":{"text":"Create Docker group and add user","parent":"ff6eb569-815f-4ea3-a6d9-a29801b13f1a","script":"# Create the docker group.\nsudo groupadd docker\n\n# Add your user to the docker group.\nsudo usermod -aG docker ${USER}\n\n# You would need to log out and log back in so that your group membership is re-evaluated or type the following command:\n# Verify that you can run docker commands without sudo.\nsudo su -c 'docker run hello-world' - ${USER}","description":{"ops":[{"insert":"Create Docker group and add current user (ubuntu) so that you do not need to run Docker as root. Run this as the user who has sudo privilege.\n"}]},"id":"36986302-75fc-49cc-b9dd-9db8d13a96f6","type":"code","variables":{}},"d6ade05b-b6e3-414f-8fa4-29b14a10e3ff":{"text":"Install Kubernetes on Ubuntu 20.04","parent":"0eeabd9e-1b19-41b5-bbc2-327a95461f81","script":"# ~~~~~ Step 1: Update the system ~~~~~\nsudo apt update\n\n# ~~~~~ Step 2: Install kubeadm, kubelet, and kubectl ~~~~~\nsudo apt-get install -y apt-transport-https ca-certificates curl\n\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n\nsudo touch /etc/apt/sources.list.d/kubernetes.list\nsudo chown ubuntu:ubuntu /etc/apt/sources.list.d/kubernetes.list\nsudo echo 'deb https://apt.kubernetes.io/ kubernetes-xenial main' > /etc/apt/sources.list.d/kubernetes.list\n\nsudo apt-get update\n\nsudo apt-get install -y kubelet kubeadm kubectl\nsudo apt-mark hold kubelet kubeadm kubectl\n\n# ~~~~~ Step 2b ~~~~~\n# https://serverfault.com/questions/1124015/kubeadm-is-showing-error-cri\nsudo rm /etc/containerd/config.toml\nsudo systemctl restart containerd\n\n# ~~~~~ Step 2c: turn off swap ~~~~~\nsudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab\nsudo swapoff -a\n\n# ~~~~~ Step 3: Initialize Kubernetes. Note down the kubeadm join command that appears at the end of the output. You will need it to join worker nodes to the cluster. ~~~~~\nsudo kubeadm init --pod-network-cidr=192.168.0.0/16\n\n# ~~~~~ Step 4: Configure kubectl ~~~~~\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n# ~~~~~ Step 5: Install a Pod network add-on ~~~~~\nkubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml\n\n# ~~~~~ Step 6: Join worker nodes (Optional) ~~~~~\n# ~~~~~ If you want to add worker nodes to the Kubernetes cluster, you can do so by running the kubeadm join command that you noted down in Step 3 on each worker node. ~~~~~\n\n# ~~~~~ Step 7: Verify the installation. You should see the master node and any worker nodes that you added. ~~~~~\nkubectl get nodes\n","description":{"ops":[{"insert":"Kubernetes is a popular open-source container orchestration system that automates deployment, scaling, and management of containerized applications. It is widely used in the industry to manage and deploy cloud-native applications.\n\nPrerequisites:\nA server running Ubuntu 20.04 with at least 2 CPU cores and 4GB of RAM."},{"attributes":{"list":"bullet"},"insert":"\n"},{"insert":"A non-root user with sudo privileges."},{"attributes":{"list":"bullet"},"insert":"\n"},{"insert":"Docker installed on the server."},{"attributes":{"list":"bullet"},"insert":"\n"},{"insert":"\nIf you want to add worker nodes to the Kubernetes cluster, you can do so by running the kubeadm join command, that you need to record after Step 3, on each worker node.\n"},{"attributes":{"link":"https://www.learnitguide.net/2023/04/how-to-install-kubernetes-on-ubuntu-2004.html"},"insert":"https://www.learnitguide.net/2023/04/how-to-install-kubernetes-on-ubuntu-2004.html"},{"insert":"\n"}]},"id":"d6ade05b-b6e3-414f-8fa4-29b14a10e3ff","type":"code","variables":{},"sort":3},"c389e4eb-5c23-49e5-989e-94f5cffff2f5":{"text":"Turn off swap","parent":"d6ade05b-b6e3-414f-8fa4-29b14a10e3ff","script":"sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab\nsudo swapoff -a","description":{"ops":[{"insert":"Part of the official requirements for Kubernetes is to disable swap space completely before attempting to launch Kubernetes.\n"},{"attributes":{"link":"https://linuxconfig.org/how-to-disable-swap-in-linux-for-kubernetes"},"insert":"https://linuxconfig.org/how-to-disable-swap-in-linux-for-kubernetes"},{"insert":"\n"}]},"id":"c389e4eb-5c23-49e5-989e-94f5cffff2f5","type":"code","variables":{},"sort":0},"2dd136ac-c1c2-4296-89fb-8348d677a968":{"text":"Docker Images","parent":"0eeabd9e-1b19-41b5-bbc2-327a95461f81","script":"","description":{"ops":[{"insert":"Docker images are a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings.\n"}]},"id":"2dd136ac-c1c2-4296-89fb-8348d677a968","type":"code","variables":{},"sort":1},"4f53a97d-feb6-4043-901d-c77a33992019":{"parent":"2dd136ac-c1c2-4296-89fb-8348d677a968","text":"Show Docker Images","hist":[{"username":"admin","ds":"2023-10-01T16:49:53.549Z","fromId":"37fe87c3-ca2d-4f00-a97c-83247a31f76e"}],"variables":{},"script":"docker images","sort":1,"id":"4f53a97d-feb6-4043-901d-c77a33992019","type":"code","description":{"ops":[{"insert":"List local images\n"}]}},"b3e893d5-7838-43af-9473-99d9845b6a1a":{"text":"Delete a Docker Image","parent":"2dd136ac-c1c2-4296-89fb-8348d677a968","script":"docker rmi {{c.image_name}}","description":{"ops":[{"insert":"Delete an Image\n"}]},"id":"b3e893d5-7838-43af-9473-99d9845b6a1a","type":"code","variables":{"image_name":{"private":false,"ask":true,"type":"Text","value":"myNonExistantImage"}},"sort":3},"049766f3-4852-4faf-bd2e-d3269c95d0ca":{"parent":"2dd136ac-c1c2-4296-89fb-8348d677a968","text":"Docker pull image","hist":[{"username":"admin","ds":"2023-10-01T16:55:41.330Z","fromId":"2e762ba5-5b75-4bb9-a80f-0c1f04217e33"}],"variables":{"image_name":{"private":false,"ask":false,"type":"Text","value":"nginx"}},"script":"docker pull {{c.image_name}}","sort":0,"id":"049766f3-4852-4faf-bd2e-d3269c95d0ca","type":"code","description":{"ops":[{"insert":"\n"}]}},"a191643a-9771-42a9-a28a-dfda98c0276b":{"parent":"2dd136ac-c1c2-4296-89fb-8348d677a968","text":"Docker build","hist":[{"username":"admin","ds":"2023-10-01T17:09:08.331Z","fromId":"049766f3-4852-4faf-bd2e-d3269c95d0ca"}],"variables":{"directory":{"private":false,"ask":false,"type":"Text","value":"/home/ubuntu/myDockerFile"}},"script":"docker build {{c.directory}}","sort":2,"id":"a191643a-9771-42a9-a28a-dfda98c0276b","type":"code","description":{"ops":[{"insert":"The docker build command builds Docker images from a Dockerfile and a \"context\". A build's context is the set of files located in the specified PATH or URL. The build process can refer to any of the files in the context. For example, your build can use a COPY instruction to reference a file in the context.\n"}]}},"520eea4f-ea9e-46a8-b715-d998bf95ae69":{"text":"Docker containers","parent":"0eeabd9e-1b19-41b5-bbc2-327a95461f81","script":"","description":{"ops":[{"insert":"Container images become containers at runtime and in the case of Docker containers – images become containers when they run on Docker Engine. \n"}]},"id":"520eea4f-ea9e-46a8-b715-d998bf95ae69","type":"code","variables":{},"sort":2},"5cc08b34-ebd7-4837-af96-22e862d49858":{"text":"Docker run","parent":"520eea4f-ea9e-46a8-b715-d998bf95ae69","script":"docker run --detach --name {{c.name}} {{c.image}}","description":{"ops":[{"insert":"This command will run container, from an image, in the background. Specify a name for the container.\n"}]},"id":"5cc08b34-ebd7-4837-af96-22e862d49858","type":"code","variables":{"image":{"private":false,"ask":false,"type":"Text","value":"nginx","idn":"0"},"name":{"private":false,"ask":false,"type":"Text","value":"web","idn":"1"}},"sort":0},"761c1cbe-2505-493c-8221-87e2e5ed960a":{"text":"Show running Docker containers","parent":"520eea4f-ea9e-46a8-b715-d998bf95ae69","script":"docker ps -a","description":{"ops":[{"insert":"Show a list of all Docker containers\n"}]},"id":"761c1cbe-2505-493c-8221-87e2e5ed960a","type":"code","variables":{},"sort":1},"33e53857-3391-4d4f-b3d4-5be9389e2bd6":{"text":"Stop Docker container","parent":"520eea4f-ea9e-46a8-b715-d998bf95ae69","script":"docker stop {{c.container}}","description":{"ops":[{"insert":"Stops a running container\n"}]},"id":"33e53857-3391-4d4f-b3d4-5be9389e2bd6","type":"code","variables":{"container":{"private":false,"ask":false,"type":"Text","value":"web"}},"sort":3},"a10afba1-c11e-4fe5-bb64-894157253567":{"parent":"520eea4f-ea9e-46a8-b715-d998bf95ae69","text":"Start Docker container","hist":[{"username":"admin","ds":"2023-10-01T17:56:53.038Z","fromId":"33e53857-3391-4d4f-b3d4-5be9389e2bd6"}],"variables":{"container":{"private":false,"ask":false,"type":"Text","value":"web","idn":"0"}},"script":"docker start {{c.container}}","sort":4,"id":"a10afba1-c11e-4fe5-bb64-894157253567","type":"code","description":{"ops":[{"insert":"\n"}]},"found":true},"e595aaed-01d8-4776-91f6-f6c7aafcf007":{"text":"Start shell in Docker container","parent":"520eea4f-ea9e-46a8-b715-d998bf95ae69","script":"docker exec -it {{c.name}} bash -c \"echo 'PS1=[ceStack]\\$PS1' > rc\" \ndocker exec -it {{c.name}} bash --rcfile rc","description":{"ops":[{"insert":"Start a shell in a running container\n"}]},"id":"e595aaed-01d8-4776-91f6-f6c7aafcf007","type":"code","variables":{"name":{"private":false,"ask":false,"type":"Text","value":"web","idn":"0"}},"sort":2,"found":true},"67696a15-7ea9-4b96-8f19-5481b355cac8":{"text":"Exit shell","parent":"e595aaed-01d8-4776-91f6-f6c7aafcf007","script":"exit","description":{"ops":[{"insert":"\n"}]},"id":"67696a15-7ea9-4b96-8f19-5481b355cac8","type":"code","variables":{},"found":true},"08619457-baa5-486b-a8cb-748cbfbd0265":{"text":"LXD","parent":"6f4987e7-6eaa-495b-be96-964645c23612","script":"","description":{"ops":[{"insert":"LXD is an open source container management extension for Linux Containers (LXC). LXD both improves upon existing LXC features and provides new features and functionality to build and manage Linux containers.\n\nLXD system containers run a complete filesystem with background processes. This allows you to run any workload, or containerise your traditional systems and apps without modifying the apps or your operations. LXD containers offer the density and efficiency of containers with a VM-like experience.\n\n"},{"attributes":{"link":"https://ubuntu.com/lxd"},"insert":"https://ubuntu.com/lxd"},{"insert":"\n"}]},"id":"08619457-baa5-486b-a8cb-748cbfbd0265","type":"code","variables":{}},"fe88d8e9-91f9-4a40-b7de-924d475aae13":{"text":"Install LXD","parent":"08619457-baa5-486b-a8cb-748cbfbd0265","script":"sudo apt update\nsudo apt install lxd\nsudo adduser $USER lxd\n\n#use the following newgrp command to apply for group memberships immediately:\nnewgrp lxd\nid\nlxc list","description":{"ops":[{"insert":"How To Install LXD on Ubuntu 20.04 LTS using apt.\nNote that after installing you may need to close and reopen session. (Reload Consol window)\n"},{"attributes":{"link":"https://www.cyberciti.biz/faq/install-lxd-on-ubuntu-20-04-lts-using-apt/"},"insert":"https://www.cyberciti.biz/faq/install-lxd-on-ubuntu-20-04-lts-using-apt/"},{"insert":"\n"}]},"id":"fe88d8e9-91f9-4a40-b7de-924d475aae13","type":"code","variables":{}},"cbf2d035-3b85-4150-ac47-34f44f2a61df":{"text":"Setup server","parent":"08619457-baa5-486b-a8cb-748cbfbd0265","script":"lxd init --auto\n\nlxc profile list\n\nlxc network list\n\nlxc storage list\n","description":{"ops":[{"insert":"\n"}]},"id":"cbf2d035-3b85-4150-ac47-34f44f2a61df","type":"code","variables":{}},"e08f3dd9-b524-4097-9cfa-479aa1a66817":{"text":"List images","parent":"08619457-baa5-486b-a8cb-748cbfbd0265","script":"lxc image list images: | grep -i {{c.filter}}","description":{"ops":[{"insert":"List images and filter by keyword.\n"}]},"id":"e08f3dd9-b524-4097-9cfa-479aa1a66817","type":"code","variables":{"filter":{"private":false,"ask":false,"type":"Text","value":"ubuntu","idn":"0"}}},"4171c582-86c0-42ef-9881-db2a0686175f":{"text":"LXD containers","parent":"08619457-baa5-486b-a8cb-748cbfbd0265","script":"","description":{"ops":[{"insert":"LXD (pronounced lex-dee) is the lightervisor, or lightweight container hypervisor. LXC (lex-see) is a program which creates and administers “containers” on a local system. It also provides an API to allow higher level managers, such as LXD, to administer containers. In a sense, one could compare LXC to QEMU, while comparing LXD to libvirt.\n\nThe LXC API deals with a ‘container’. The LXD API deals with ‘remotes’, which serve images and containers. This extends the LXC functionality over the network, and allows concise management of tasks like container migration and container image publishing.\n\nLXD uses LXC under the covers for some container management tasks. However, it keeps its own container configuration information and has its own conventions, so that it is best not to use classic LXC commands by hand with LXD containers. This document will focus on how to configure and administer LXD on Ubuntu systems.\n"}]},"id":"4171c582-86c0-42ef-9881-db2a0686175f","type":"code","variables":{}},"a51da776-b7f1-4bbb-a11b-e2c096f9e31c":{"parent":"4171c582-86c0-42ef-9881-db2a0686175f","text":"Create LXD container","hist":[{"username":"admin","ds":"2023-10-01T18:49:42.446Z","fromId":"0c171e68-d726-4306-bbb5-72d746abdf0e"}],"variables":{"image":{"private":false,"ask":false,"type":"Text","value":"ubuntu/focal/amd64 ubuntu-focal-c5","idn":"0"}},"script":"lxc launch images:{{c.image}}\nlxc list","sort":0,"id":"a51da776-b7f1-4bbb-a11b-e2c096f9e31c","type":"code","description":{"ops":[{"insert":"Containers are a lightweight virtualization technology. They are more akin to an enhanced chroot than to full virtualization like Qemu or VMware, both because they do not emulate hardware and because containers share the same operating system as the host. Containers are similar to Solaris zones or BSD jails. Linux-vserver and OpenVZ are two pre-existing, independently developed implementations of containers-like functionality for Linux. In fact, containers came about as a result of the work to upstream the vserver and OpenVZ functionality.\nThere are two user-space implementations of containers, each exploiting the same kernel features. Libvirt allows the use of containers through the LXC driver by connecting to "},{"attributes":{"color":"inherit","background":"rgba(0, 0, 0, 0.03)","code":true},"insert":"lxc:///"},{"insert":". This can be very convenient as it supports the same usage as its other drivers. The other implementation, called simply ‘LXC’, is not compatible with libvirt, but is more flexible with more userspace tools. It is possible to switch between the two, though there are peculiarities which can cause confusion.\n"},{"attributes":{"link":"https://ubuntu.com/server/docs/containers-lxc"},"insert":"https://ubuntu.com/server/docs/containers-lxc"},{"insert":"\n"}]}},"48c67eb4-a6bd-4eb8-9603-c02e88e7ec68":{"text":"Start LXD shell","parent":"4171c582-86c0-42ef-9881-db2a0686175f","script":"lxc exec {{c.name}} -- bash -c \"echo 'PS1=[ceStack]\\$PS1' > rc\" \nlxc exec {{c.name}} -- bash --rcfile rc","description":{"ops":[{"insert":"Open a command prompt in an LXD container. Change the prompt to include [ceStack]\n"}]},"id":"48c67eb4-a6bd-4eb8-9603-c02e88e7ec68","type":"code","variables":{"name":{"private":false,"ask":false,"type":"Text","value":"ubuntu-focal-c5","idn":"0"}},"sort":2,"found":true},"340d0d2d-8cf9-47aa-a104-f544dfabd1c8":{"parent":"48c67eb4-a6bd-4eb8-9603-c02e88e7ec68","text":"Exit shell","hist":[{"username":"admin","ds":"2023-10-01T18:53:15.741Z","fromId":"67696a15-7ea9-4b96-8f19-5481b355cac8"}],"variables":{},"script":"exit","sort":0,"id":"340d0d2d-8cf9-47aa-a104-f544dfabd1c8","type":"code"},"0266a1e6-7f51-4f1f-b81c-dbc3b6bacc5a":{"parent":"4171c582-86c0-42ef-9881-db2a0686175f","text":"Stop LXD container","hist":[{"username":"admin","ds":"2023-10-01T18:54:14.437Z","fromId":"48c67eb4-a6bd-4eb8-9603-c02e88e7ec68"}],"variables":{"name":{"private":false,"ask":false,"type":"Text","value":"ubuntu-focal-c5","idn":"0"}},"script":"lxc stop {{c.name}}","sort":3,"id":"0266a1e6-7f51-4f1f-b81c-dbc3b6bacc5a","type":"code","description":{"ops":[{"insert":"\n"}]}},"bcb8bc31-ef9a-40f3-a37e-54fdae551c44":{"parent":"4171c582-86c0-42ef-9881-db2a0686175f","text":"Start LXD container","hist":[{"username":"admin","ds":"2023-10-01T18:54:58.830Z","fromId":"0266a1e6-7f51-4f1f-b81c-dbc3b6bacc5a"}],"variables":{"name":{"private":false,"ask":false,"type":"Text","value":"ubuntu-focal-c5","idn":"0"}},"script":"lxc start {{c.name}}","sort":4,"id":"bcb8bc31-ef9a-40f3-a37e-54fdae551c44","type":"code","description":{"ops":[{"insert":"\n"}]},"found":true},"bb001953-92e4-4f4f-878a-5ad60f9d5019":{"parent":"4171c582-86c0-42ef-9881-db2a0686175f","text":"Delete LXD container","hist":[{"username":"admin","ds":"2023-10-01T18:56:44.154Z","fromId":"0266a1e6-7f51-4f1f-b81c-dbc3b6bacc5a"}],"variables":{"name":{"private":false,"ask":false,"type":"Text","value":"ubuntu-focal-c5","idn":"0"}},"script":"lxc delete {{c.name}} --force","sort":5,"id":"bb001953-92e4-4f4f-878a-5ad60f9d5019","type":"code","description":{"ops":[{"insert":"Stops container with force so that the container does not need to be stopped first.\n"}]}},"75b44781-a0b1-4a26-b58e-7ecc90e0049d":{"parent":"4171c582-86c0-42ef-9881-db2a0686175f","text":"List LXD container","hist":[{"username":"admin","ds":"2023-10-01T18:59:24.470Z","fromId":"0266a1e6-7f51-4f1f-b81c-dbc3b6bacc5a"}],"variables":{},"script":"lxc list ","sort":1,"id":"75b44781-a0b1-4a26-b58e-7ecc90e0049d","type":"code","description":{"ops":[{"insert":"\n"}]}},"0a7dc826-afcc-489f-a570-db7714355e9a":{"parent":"d6ade05b-b6e3-414f-8fa4-29b14a10e3ff","text":"Deploy Calico pod network to the cluster","hist":[{"username":"admin","ds":"2023-10-02T13:29:43.764Z","fromId":"af3bb472-45ad-4c98-895b-5a347016b669"}],"variables":{},"script":"# Install the Tigera Calico operator and custom resource definitions.\n\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml\n\n\n# NOTE\n# Due to the large size of the CRD bundle, kubectl apply might exceed request limits. Instead, use kubectl create or kubectl replace.\n\n# Install Calico by creating the necessary custom resource. For more information on configuration options available in this manifest, see the installation reference.\n\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/custom-resources.yaml\n\n\n# NOTE\n# Before creating this manifest, read its contents and make sure its settings are correct for your environment. \n# For example, you may need to change the default IP pool CIDR to match your pod network CIDR.\n\n# Confirm that all of the pods are running with the following command.\n\n# !!!!! WAIT until each pod has the STATUS of Running. Then press any key !!!!\nuntil read -s -n 1 -t 0.01; do kubectl get pods -n calico-system;echo \"\"; sleep 5; done; echo \n\n# NOTE The Tigera operator installs resources in the calico-system namespace. Other install methods may use the kube-system namespace instead.\n\n# Remove the taints on the control plane so that you can schedule pods on it.\n\nkubectl taint nodes --all node-role.kubernetes.io/control-plane-\nkubectl taint nodes --all node-role.kubernetes.io/master-\n\n# It should return the following.\n# node/<your-hostname> untainted\n\n# Confirm that you now have a node in your cluster with the following command.\n\nkubectl get nodes -o wide\n\n# It should return something like the following.\n\n# NAME              STATUS   ROLES    AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION    CONTAINER-RUNTIME\n# <your-hostname>   Ready    master   52m   v1.12.2   10.128.0.28   <none>        Ubuntu 18.04.1 LTS","sort":1,"id":"0a7dc826-afcc-489f-a570-db7714355e9a","type":"code","description":{"ops":[{"insert":"\n"}]}},"c6fb262b-a15f-47d1-a402-7c98bf6c0108":{"parent":"0a7dc826-afcc-489f-a570-db7714355e9a","text":"Show node in your cluster","hist":[{"username":"admin","ds":"2023-10-02T13:29:43.765Z","fromId":"779d0071-bdc1-44af-801d-d3dc1be2dcca"}],"variables":{},"script":"# Confirm that you now have a node in your cluster with the following command.\n\nkubectl get nodes -o wide","id":"c6fb262b-a15f-47d1-a402-7c98bf6c0108","type":"code","description":{"ops":[{"insert":"\n"}]}},"89f9d3d2-81a0-4377-bfb2-b7c9f28347dc":{"parent":"8f115abd-a0f1-4bd0-951e-d36d69229f31","text":"Test 24","description":{"ops":[{"insert":"mn,n,\n"}]},"hist":[{"username":"admin","ds":"2023-10-02T14:21:57.178Z","fromId":"ea841508-edb1-4fd7-aca1-46fbb21a97a3"}],"variables":{"test2":{"private":true,"ask":false,"type":"Text","value":"","idn":"0"}},"script":"","sort":1,"id":"89f9d3d2-81a0-4377-bfb2-b7c9f28347dc","type":"code","found":true},"f6cee730-3ba2-483a-ab20-a585add2130a":{"text":"Art","parent":"b1e874e9-a642-4920-8624-355118328fb1","script":"sudo apt -y install lolcat\nsudo apt-get -y install konwert\n\ncd ~\nmkdir ascii\ncd ascii\n\ngit clone https://github.com/PhMajerus/ANSI-art\n\ncd ANSI-art/\n\nls | lolcat\n\n\nfor FILE in *.ans; do \n- echo;echo $FILE | lolcat; \n- cat \"$FILE\" | konwert cp437-UTF8 | sed 'H;$!d;x;s/\\x1A.*$//';\n- sleep 3;\n-done\nfor FILE in *.txt; do \n- echo;echo $FILE; \n- cat \"$FILE\" ;\n- sleep 3;\n-done\n# for FILE in Unicode/*.txt; do \n# - echo;echo \"$FILE\"; \n# - cat \"$FILE\" ;\n# -done\n","description":{"ops":[{"insert":"Install lolcat and download and display some sample asciii art. \n"}]},"id":"f6cee730-3ba2-483a-ab20-a585add2130a","type":"code","variables":{},"found":true},"f859158f-b593-499f-9841-1a0c809f4fec":{"text":"Dev","parent":"#","script":"","description":{"ops":[{"insert":"Build things dev\n"}]},"id":"f859158f-b593-499f-9841-1a0c809f4fec","type":"code","variables":{},"sort":2},"d07995d0-0d2f-4d91-b0e0-943a8ff76cfb":{"text":"Node.js","parent":"f859158f-b593-499f-9841-1a0c809f4fec","script":"","description":{"ops":[{"insert":"\nIn a nutshell, Node. js is a popular programming environment that can be used for building high-scale applications that need to support multiple concurrent requests. Single-threaded non-blocking I/O makes it an excellent choice for both real-time and data streaming applications, too.\n"},{"attributes":{"link":"https://nodejs.org/en"},"insert":"https://nodejs.org/en"},{"insert":"\n"}]},"id":"d07995d0-0d2f-4d91-b0e0-943a8ff76cfb","type":"code","variables":{},"sort":1},"a95cf7f6-146a-4106-8595-c8c0cb43c0f2":{"parent":"d07995d0-0d2f-4d91-b0e0-943a8ff76cfb","text":"Install Node.js","description":{"ops":[{"insert":"Download package and install.\n"}]},"hist":[{"username":"admin","ds":"2023-10-08T17:25:10.127Z","fromId":"fae372dd-8689-433d-950d-47b094ed067c"}],"variables":{"version":{"private":false,"ask":false,"type":"Text","value":"18"}},"script":"sudo apt update\ncurl -sL https://deb.nodesource.com/setup_{{c.version}}.x | sudo bash -\nsudo apt -y install nodejs","sort":0,"id":"a95cf7f6-146a-4106-8595-c8c0cb43c0f2","type":"code"},"4df72939-018e-463b-8c71-27e6057ade3c":{"text":"Initialize Node project","parent":"d07995d0-0d2f-4d91-b0e0-943a8ff76cfb","script":"\nnpm init -y","description":{"ops":[{"insert":"NPM is the package manager tool commonly used in the Node world. We will use it to create a new Node project. The new project information is stored in package.json.\nIf package.json already exists the dependencies listed in it will be installed. \n"}]},"id":"4df72939-018e-463b-8c71-27e6057ade3c","type":"code","variables":{},"sort":2},"126cbb97-d8c2-42d5-8985-58ec59eb9f8d":{"text":"Install Midnight Commander","parent":"b1e874e9-a642-4920-8624-355118328fb1","script":"sudo apt -y install mc","description":{"ops":[{"insert":"GNU Midnight Commander is a visual file manager, licensed under GNU General Public License and therefore qualifies as Free Software. It's a feature rich full-screen text mode application that allows you to copy, move and delete files and whole directory trees, search for files and run commands in the subshell. Internal viewer and editor are included.\n"},{"attributes":{"link":"https://midnight-commander.org/"},"insert":"https://midnight-commander.org/"},{"insert":"\nType mc to start.  Type exit to exit mc.\n"}]},"id":"126cbb97-d8c2-42d5-8985-58ec59eb9f8d","type":"code","variables":{}},"cee2ea15-d153-4954-94fc-f098fe536d5b":{"parent":"f859158f-b593-499f-9841-1a0c809f4fec","text":"Git","description":{"ops":[{"insert":"Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency.\n\nGit is easy to learn and has a tiny footprint with lightning fast performance. It outclasses SCM tools like Subversion, CVS, Perforce, and ClearCase with features like cheap local branching, convenient staging areas, and multiple workflows.\n\n"},{"attributes":{"link":"https://git-scm.com/"},"insert":"https://git-scm.com/"},{"insert":"\n\nSee also:\n"},{"attributes":{"link":"https://github.com/"},"insert":"https://github.com/"},{"insert":"\nGitHub is an online software development platform. It's used for storing, tracking, and collaborating on software projects. It makes it easy for developers to share code files and collaborate with fellow developers on open-source projects.\n"}]},"hist":[{"username":"admin","ds":"2023-10-11T20:12:01.842Z","fromId":"b69ec905-de6c-4f2e-a1b7-8efcb87b649d"}],"variables":{},"script":"","sort":0,"id":"cee2ea15-d153-4954-94fc-f098fe536d5b","type":"code"},"893feb17-b05f-451e-ab5b-a7ee7546e2b4":{"parent":"cee2ea15-d153-4954-94fc-f098fe536d5b","text":"git clone","description":{"ops":[{"insert":"git clone is primarily used to point to an "},{"attributes":{"underline":true,"bold":true},"insert":"existing"},{"insert":" repo and make a clone or copy of that repo at in a new directory, at another location. The original repository can be located on the local filesystem or on remote machine accessible supported protocols (like github).\n\nIf the repository is private you will need to enter your github user id and your access token.\nIf you do not have an access token see "},{"attributes":{"link":"https://www.google.com/search?q=github+how+to+generate+personal+access+token"},"insert":"https://www.google.com/search?q=github+how+to+generate+personal+access+token"},{"insert":"\n"}]},"hist":[{"username":"admin","ds":"2023-10-11T20:12:01.842Z","fromId":"e869ec45-c119-4247-82d9-ab173c7a2de9"}],"variables":{"repo":{"private":false,"ask":false,"type":"Text","value":"https://github.com/cybera/data-science-template","idn":"0"}},"script":"\ngit clone {{c.repo}}","id":"893feb17-b05f-451e-ab5b-a7ee7546e2b4","type":"code","sort":2},"172e6557-9aae-4bab-9501-dc61a39976a8":{"parent":"cee2ea15-d153-4954-94fc-f098fe536d5b","text":"git init","description":{"ops":[{"insert":"The git init command creates a "},{"attributes":{"underline":true,"bold":true},"insert":"new"},{"insert":" Git repository. It can be used to convert an existing, unversioned project to a Git repository or initialize a new, empty repository. Most other Git commands are not available outside of an initialized repository, so this is usually the first command you'll run in a new project.\n"}]},"hist":[{"username":"admin","ds":"2023-10-11T20:12:01.842Z","fromId":"e4d5b512-5864-4ff7-9f08-333e3ef6183a"}],"variables":{},"script":"\ngit init","id":"172e6557-9aae-4bab-9501-dc61a39976a8","type":"code","sort":1},"c32e3f2a-bb0f-4f43-9e71-312bcbcade39":{"parent":"172e6557-9aae-4bab-9501-dc61a39976a8","text":"git status, git add","description":{"ops":[{"insert":"The git status command displays the state of the working directory and the staging area. It lets you see which changes have been staged, which haven't, and which files aren't being tracked by Git. Status output does not show you any information regarding the committed project history.\n\nThe git add command adds a change in the working directory to the staging area. It tells Git that you want to include updates to a particular file in the next commit. However, git add doesn't really affect the repository in any significant way—changes are not actually recorded until you run git commit.\n"}]},"hist":[{"username":"admin","ds":"2023-10-11T20:12:01.842Z","fromId":"f875a0ab-5770-4597-b259-8162a1970967"}],"variables":{"folder":{"private":false,"ask":false,"type":"Text","value":"test","idn":"0"}},"script":"cd ~/{{c.folder}}\ngit status\n\necho \"Enter 'git add' followed by the folder/fileNames of all the files that should be pushed\"","id":"c32e3f2a-bb0f-4f43-9e71-312bcbcade39","type":"code","sort":2},"290b0e7d-3b9d-48a1-a710-edcc7f7bebe2":{"parent":"172e6557-9aae-4bab-9501-dc61a39976a8","text":"git log","description":{"ops":[{"insert":" git log lists the commits made in that repository in reverse chronological order; that is, the most recent commits show up first. As you can see, this command lists each commit with its SHA-1 checksum, the author's name and email, the date written, and the commit message. Type q to quit ui.\n"}]},"hist":[{"username":"admin","ds":"2023-10-11T20:12:01.842Z","fromId":"2fe0e4f8-4385-4eee-9d0a-0f2b98e75a40"}],"variables":{},"script":"git log","id":"290b0e7d-3b9d-48a1-a710-edcc7f7bebe2","type":"code","sort":3},"c18e296f-0e25-4f79-9d3e-183210e09e4b":{"parent":"172e6557-9aae-4bab-9501-dc61a39976a8","text":"git pull","description":{"ops":[{"insert":"The git pull command is used to fetch and download content from a remote repository and immediately update the local repository to match that content. Merging remote upstream changes into your local repository is a common task in Git-based collaboration work flows.\n"}]},"hist":[{"username":"admin","ds":"2023-10-11T20:13:18.700Z","fromId":"290b0e7d-3b9d-48a1-a710-edcc7f7bebe2"}],"variables":{"folder":{"private":false,"ask":false,"type":"Text","value":"test","idn":"1"},"repo":{"private":false,"ask":false,"type":"Text","value":"https://github.com/cybera/adsl-cohort-workshops.git"}},"script":"cd ~\nmkdir {{c.folder}}\ncd {{c.folder}}\ngit pull {{c.repo}}\nls","sort":1,"id":"c18e296f-0e25-4f79-9d3e-183210e09e4b","type":"code"},"2ae7e04f-fa17-4222-acee-ed41c6ba0740":{"text":"Anaconda","parent":"f859158f-b593-499f-9841-1a0c809f4fec","script":"\n","description":{"ops":[{"attributes":{"bold":true},"insert":"Accelerate Your Team’s AI Projects, From Concept to Production."},{"insert":"\nEffortlessly transition from idea to deployment while upholding security standards. Anaconda’s AI and data science platform empowers teams to own the entire project lifecycle—no IT hand-offs, no deployment headaches. Share actionable insights instantly with decision-makers simply by sharing a link to your application.  \n"},{"attributes":{"link":"https://www.anaconda.com/"},"insert":"https://www.anaconda.com/"},{"insert":"\n\nWarning: Anaconda is slow.\n"}]},"id":"2ae7e04f-fa17-4222-acee-ed41c6ba0740","type":"code","variables":{}},"9f57e6c4-f3d0-4a02-abf4-8ce0d28bb04d":{"text":"conda init","parent":"2ae7e04f-fa17-4222-acee-ed41c6ba0740","script":"~/anaconda3/bin/conda init","description":{"ops":[{"insert":"conda init will initialize a shell "},{"attributes":{"italic":true},"insert":"permanently"},{"insert":" by writing some shell code in the relevant startup scripts of your shell (e.g. ~/.bashrc).\n"},{"attributes":{"link":"https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/activation.html"},"insert":"https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/activation.html"},{"insert":"\n\nTo use the new shell config, you will need to exit shell (execute \"exit\" in console) and then reconnect.\n\nAfter you reconnect you will see \"(base)\" in the command prompt.\n"}]},"id":"9f57e6c4-f3d0-4a02-abf4-8ce0d28bb04d","type":"code","variables":{},"sort":1},"fe38fd07-46aa-49f0-83cb-475120566048":{"parent":"2ae7e04f-fa17-4222-acee-ed41c6ba0740","text":"Install Anaconda","description":{"ops":[{"insert":"On ubuntu\n\nDuring the install you will be prompted to: \nreview and agree to its license agreement before the installation will continue. Hit Enter to continue. Pressing the space bar a few times will bring you to the end of the license agreement, where you can accept the terms. Type in “yes” as highlighted and hit Enter."},{"attributes":{"list":"ordered"},"insert":"\n"},{"insert":"Confirm install to /home/ubuntu. Hit Enter (Yes)."},{"attributes":{"list":"ordered"},"insert":"\n"},{"insert":"Execute conda init. Hit Enter (No)."},{"attributes":{"list":"ordered"},"insert":"\n"}]},"hist":[{"username":"admin","ds":"2023-10-12T17:03:10.581Z","fromId":"9f57e6c4-f3d0-4a02-abf4-8ce0d28bb04d"}],"variables":{},"script":"sudo apt-get update\ncd /tmp\nsudo apt-get -y -qq install wget\n\nwget https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh\nsudo chmod +x Anaconda3-2023.09-0-Linux-x86_64.sh\n./Anaconda3-2023.09-0-Linux-x86_64.sh\n","sort":0,"id":"fe38fd07-46aa-49f0-83cb-475120566048","type":"code"},"0a729025-2e56-4522-931c-fabed8ec067b":{"text":"conda install -packages-","parent":"2ae7e04f-fa17-4222-acee-ed41c6ba0740","script":"# conda install -y -c conda-forge {{c.packages}}\nconda install -y {{c.packages}}","description":{"ops":[{"attributes":{"link":"https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/install.html"},"insert":"https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/install.html"},{"insert":"\nInstall a list of packages into a specified conda environment. This command accepts a list of package specifications (e.g, bitarray=0.8) and installs a set of packages consistent with those specifications and compatible with the underlying environment.\n"}]},"id":"0a729025-2e56-4522-931c-fabed8ec067b","type":"code","variables":{"packages":{"private":false,"ask":false,"type":"Text","value":"scipy"}},"sort":5},"ab0d10ed-f7b0-4355-a290-6e0c8ebbcc89":{"text":"conda info","parent":"2ae7e04f-fa17-4222-acee-ed41c6ba0740","script":"conda info","description":{"ops":[{"insert":"info about your conda install\n"}]},"id":"ab0d10ed-f7b0-4355-a290-6e0c8ebbcc89","type":"code","variables":{},"sort":2},"d4b84f33-40ae-4a30-8108-5e83ab5a635b":{"text":"conda update","parent":"2ae7e04f-fa17-4222-acee-ed41c6ba0740","script":"conda update -y -n base conda\nconda update -y anaconda","description":{"ops":[{"insert":"conda update to latest version\n"}]},"id":"d4b84f33-40ae-4a30-8108-5e83ab5a635b","type":"code","variables":{},"sort":3},"5d56ccbb-e6aa-4ab8-b51b-d97e3603b284":{"text":"DVC","parent":"f859158f-b593-499f-9841-1a0c809f4fec","script":"","description":{"ops":[{"attributes":{"link":"https://dvc.org/"},"insert":"https://dvc.org/"},{"insert":"\n(Not Just) Data Version Control\nOpen-source, Git-based data science. Apply version control to machine learning development, make your repo the backbone of your project, and instill best practices across your team.\n\nWhy DVC?\nEven with all the success we've seen in machine learning, especially with deep learning and its applications in business, data scientists still lack best practices for organizing their projects and collaborating effectively. This is a critical challenge: while ML algorithms and methods are no longer tribal knowledge, they are still difficult to develop, reuse, and manage.\n\nBasic uses of DVC\nIf you store and process data files or datasets to produce other data or machine learning models, and you want to \ntrack and save data and machine learning models the same way you capture code;"},{"attributes":{"list":"bullet"},"insert":"\n"},{"insert":"create and switch between versions of data and ML models easily;"},{"attributes":{"list":"bullet"},"insert":"\n"},{"insert":"understand how datasets and ML artifacts were built in the first place;"},{"attributes":{"list":"bullet"},"insert":"\n"},{"insert":"compare model metrics among experiments;"},{"attributes":{"list":"bullet"},"insert":"\n"},{"insert":"adopt engineering tools and best practices in data science projects;"},{"attributes":{"list":"bullet"},"insert":"\n"},{"insert":"DVC is for you!\n\n"},{"insert":{"image":"https://littlebigcode.fr/wp-content/uploads/2022/05/image-20220507-222806.png"}},{"insert":"\n"},{"attributes":{"link":"https://littlebigcode.fr/en/how-dvc-manages-data-sets-training-ml-models-git/"},"insert":"https://littlebigcode.fr/en/how-dvc-manages-data-sets-training-ml-models-git/"},{"insert":"\n"}]},"id":"5d56ccbb-e6aa-4ab8-b51b-d97e3603b284","type":"code","variables":{}},"27a2991b-6d6c-42ca-9af6-34b242ce8562":{"text":"DVC init","parent":"5d56ccbb-e6aa-4ab8-b51b-d97e3603b284","script":"cd ~\nmkdir {{c.folder}}\ncd {{c.folder}}\ndvc init\n\ngit status\ngit commit -m \"Initialize DVC\"\n","description":{"ops":[{"insert":"At DVC initialization, a new . dvc/ directory is created for configuration, default cache location, and other internal files and directories, that are hidden from the user. This directory is automatically staged with git add , so it can be easily committed with Git.\nEnsure you have a git repository initialized (git init) in the target folder and that git has been setup with your name and email.\n"}]},"id":"27a2991b-6d6c-42ca-9af6-34b242ce8562","type":"code","variables":{"folder":{"private":false,"ask":false,"type":"Text","value":"test","idn":"0"}},"sort":2},"3373f2ce-0faa-43c9-a4d5-0bbcf1ba6135":{"text":"git config","parent":"172e6557-9aae-4bab-9501-dc61a39976a8","script":"# Enter your email\nread -s email\ngit config --global user.email \"$email\"\n\n#Enter your name\nread -s name\ngit config --global user.name \"$name\"\n\ngit config -l #list all","description":{"ops":[{"insert":"Script to configure your email and name in git config so that you can commit changes.\n"}]},"id":"3373f2ce-0faa-43c9-a4d5-0bbcf1ba6135","type":"code","variables":{},"sort":0},"fa8820f0-2f2f-4b09-95bb-292ab569a449":{"text":"Tutorial","parent":"5d56ccbb-e6aa-4ab8-b51b-d97e3603b284","script":"","description":{"ops":[{"attributes":{"link":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},"insert":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},{"insert":"\n\nThe goal of this example is to give you some hands-on experience with a basic machine learning version control scenario: managing multiple datasets and ML models using DVC\n"}]},"id":"fa8820f0-2f2f-4b09-95bb-292ab569a449","type":"code","variables":{},"sort":3},"61e136a6-ec9a-46dc-8fcb-90b5c755fec6":{"parent":"fa8820f0-2f2f-4b09-95bb-292ab569a449","text":"Setup project folder","description":{"ops":[{"attributes":{"link":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},"insert":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},{"insert":"\n"}]},"hist":[{"username":"admin","ds":"2023-10-12T23:56:38.463Z","fromId":"fa8820f0-2f2f-4b09-95bb-292ab569a449"}],"variables":{},"script":"sudo apt -y install unzip \n\n# make a folder\nmkdir ~/tutorial\n\n# change current folder (directory) to the new folder\ncd ~/tutorial\n\n# install unzip utility\nsudo apt -y install unzip \n\n# Get the data from git by cloning the repo\ngit clone https://github.com/iterative/example-versioning.git\n\n# change current folder to the new repo\ncd example-versioning\n\n# Use pip to install what ever is listed in the requirements text file\npip install -r requirements.txt","sort":0,"id":"61e136a6-ec9a-46dc-8fcb-90b5c755fec6","type":"code"},"cb54f590-9037-4b46-90ce-3a0449738e07":{"parent":"61e136a6-ec9a-46dc-8fcb-90b5c755fec6","text":"Clone first model version and set up environment","description":{"ops":[{"attributes":{"link":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},"insert":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},{"insert":"\n"}]},"hist":[{"username":"admin","ds":"2023-10-12T23:58:05.107Z","fromId":"fa8820f0-2f2f-4b09-95bb-292ab569a449"}],"variables":{},"script":"# This command downloads and extracts the raw dataset, consisting of 1000 labeled images for training and 800 labeled images for validation. In total, it's a 43 MB dataset\ndvc get https://github.com/iterative/dataset-registry tutorials/versioning/data.zip\n\n# uncompress the data file and remove the no longer needed zip \nunzip -q data.zip\nrm -f data.zip\n\n# Add the new data folder to the list of dvc tracked items\ndvc add data\n\n# You can use this command instead of git add on files or directories that are too large to be tracked with Git\ngit add data.dvc .gitignore\n","sort":0,"id":"cb54f590-9037-4b46-90ce-3a0449738e07","type":"code"},"9c048255-1ed7-4787-b3d8-bc9e1a5f1ccd":{"parent":"cb54f590-9037-4b46-90ce-3a0449738e07","text":"Train data and commit results, tag v1","description":{"ops":[{"attributes":{"link":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},"insert":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},{"insert":"\n"}]},"hist":[{"username":"admin","ds":"2023-10-13T00:01:02.917Z","fromId":"fa8820f0-2f2f-4b09-95bb-292ab569a449"}],"variables":{},"script":"# This command outputs a bunch of files, among them model.h5 and metrics.csv, weights of the trained model, and metrics history.\npython train.py\n\n# track the model\ndvc add model.h5\n\n# commit current state\ngit add data.dvc model.h5.dvc metrics.csv .gitignore\ngit commit -m \"First model, trained with 1000 images\"\ngit tag -a \"v1.0\" -m \"model v1.0, 1000 images\"\n\n","sort":0,"id":"9c048255-1ed7-4787-b3d8-bc9e1a5f1ccd","type":"code"},"89939410-b2e5-4e6f-82a6-fb5c0a08e923":{"parent":"9c048255-1ed7-4787-b3d8-bc9e1a5f1ccd","text":"Clone second model version and set up environment","description":{"ops":[{"attributes":{"link":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},"insert":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},{"insert":"\n"}]},"hist":[{"username":"admin","ds":"2023-10-13T00:17:38.053Z","fromId":"cb54f590-9037-4b46-90ce-3a0449738e07"}],"variables":{},"script":"dvc get https://github.com/iterative/dataset-registry tutorials/versioning/new-labels.zip\nunzip -q new-labels.zip\nrm -f new-labels.zip","sort":0,"id":"89939410-b2e5-4e6f-82a6-fb5c0a08e923","type":"code"},"12ca2245-428f-484a-9265-5fcba808b3b0":{"parent":"89939410-b2e5-4e6f-82a6-fb5c0a08e923","text":"Train data and commit results, tag v2","description":{"ops":[{"attributes":{"link":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},"insert":"https://dvc.org/doc/use-cases/versioning-data-and-models/tutorial"},{"insert":"\n"}]},"hist":[{"username":"admin","ds":"2023-10-13T00:19:10.760Z","fromId":"9c048255-1ed7-4787-b3d8-bc9e1a5f1ccd"}],"variables":{},"script":"# This command outputs a bunch of files, among them model.h5 and metrics.csv, weights of the trained model, and metrics history.\npython train.py\n\n# track the model\ndvc add model.h5\n\n# commit 2nd model\ngit add data.dvc model.h5.dvc metrics.csv\ngit commit -m \"Second model, trained with 2000 images\"\ngit tag -a \"v2.0\" -m \"model v2.0, 2000 images\"\n\n","sort":0,"id":"12ca2245-428f-484a-9265-5fcba808b3b0","type":"code"},"e5097a01-ca47-4e70-b854-6ce2f6a94b6b":{"text":"Check out a version","parent":"12ca2245-428f-484a-9265-5fcba808b3b0","script":"git checkout v1.0\ndvc checkout\n\ngit status","description":{"ops":[{"insert":"The DVC command that helps get a specific committed version of data is designed to be similar to git checkout. All we need to do in our case is to additionally run dvc checkout to get the right data into the workspace.\n\n"},{"attributes":{"link":"https://littlebigcode.fr/en/how-dvc-manages-data-sets-training-ml-models-git/"},"insert":"https://littlebigcode.fr/en/how-dvc-manages-data-sets-training-ml-models-git/"},{"insert":"\n"}]},"id":"e5097a01-ca47-4e70-b854-6ce2f6a94b6b","type":"code","variables":{}},"370d4792-d910-4bb0-ae8e-fa736b127879":{"text":"CKAN","parent":"f859158f-b593-499f-9841-1a0c809f4fec","script":"","description":{"ops":[{"insert":"The Comprehensive Knowledge Archive Network (CKAN) is an open-source open data portal for the storage and distribution of open data. Initially inspired by the package management capabilities of Debian Linux, CKAN has developed into a powerful data catalogue system that is mainly used by public institutions seeking to share their data with the general public.\n\nCKAN's codebase is maintained by the Open Knowledge Foundation. The system is used both as a public platform on Datahub and in various government data catalogues, such as the UK's data.gov.uk, the Dutch National Data Register, the United States government's Data.gov and the Australian government's \"Gov 2.0\".The state government of South Australia also makes government data freely available to the public on the CKAN platform. The Italian government makes available the open data of the Data & Analytics Framework on the CKAN platform.\n\nCKAN's back end, the part running on the Web server, is written mainly in Python. The web pages it offers to users browsers include JavaScript. CKAN maintains information about the data sets to be offered to users in PostgreSQL databases. Searches are implemented by Solr. CKAN installations can be queried through Web APIs.\n\n"},{"attributes":{"link":"https://ckan.org/"},"insert":"https://ckan.org/"},{"insert":"\n"},{"attributes":{"link":"https://en.wikipedia.org/wiki/CKAN"},"insert":"https://en.wikipedia.org/wiki/CKAN"},{"insert":"\n"}]},"id":"370d4792-d910-4bb0-ae8e-fa736b127879","type":"code","variables":{}},"21a36e7a-c651-4981-97c6-f16953f5bbc6":{"parent":"2ae7e04f-fa17-4222-acee-ed41c6ba0740","text":"conda install faster solver","description":{"ops":[{"attributes":{"link":"https://www.anaconda.com/blog/a-faster-conda-for-a-growing-community"},"insert":"https://www.anaconda.com/blog/a-faster-conda-for-a-growing-community"},{"insert":"\n\nThe conda team is pleased to announce the availability of ‘libmamba’ as a new, much faster dependency solver for conda! Three different companies worked to make this release possible: QuantStack, developing mamba and libmamba; Quansight, integrating libmamba into conda; and Anaconda, developing conda and managing the overall effort. Read on to get to know the core contributors of this project, why we brought mamba’s capabilities into conda, and how you can start speeding up your workflows today.\n"}]},"hist":[{"username":"admin","ds":"2023-10-14T15:25:12.197Z","fromId":"0a729025-2e56-4522-931c-fabed8ec067b"}],"variables":{},"script":"# I tried setting the solver to a much faster solver but its hard to say if it's faster\n# https://conda.github.io/conda-libmamba-solver/getting-started/\n# https://conda.github.io/conda-libmamba-solver/libmamba-vs-classic/\nconda install -y -n base conda-libmamba-solver\nconda config --set solver libmamba\n\n","sort":4,"id":"21a36e7a-c651-4981-97c6-f16953f5bbc6","type":"code"},"00d52776-ee07-4bb0-8b2b-2e2fbfe6cff3":{"parent":"5d56ccbb-e6aa-4ab8-b51b-d97e3603b284","text":"conda install DVC","description":{"ops":[{"insert":"installs DVC via Anaconda.\nMay take several minutes.\n"}]},"hist":[{"username":"admin","ds":"2023-10-15T17:21:13.357Z","fromId":"0a729025-2e56-4522-931c-fabed8ec067b"}],"variables":{"packages":{"private":false,"ask":false,"type":"Text","value":"dvc","idn":"0"}},"script":"# conda install -y -c conda-forge {{c.packages}}\nconda install -y {{c.packages}}","sort":0,"id":"00d52776-ee07-4bb0-8b2b-2e2fbfe6cff3","type":"code"},"ed3d11e5-b716-44d3-965f-17d0e79a37b2":{"parent":"d07995d0-0d2f-4d91-b0e0-943a8ff76cfb","text":"Create new project folder","description":{"ops":[{"insert":"Create new project folder and navigate into it.\n"}]},"hist":[{"username":"admin","ds":"2023-10-15T18:14:41.529Z","fromId":"4df72939-018e-463b-8c71-27e6057ade3c"}],"variables":{"name":{"private":false,"ask":false,"type":"Text","value":"myProject","idn":"0"}},"script":"mkdir ~/{{c.name}}\ncd ~/{{c.name}}\n","sort":1,"id":"ed3d11e5-b716-44d3-965f-17d0e79a37b2","type":"code"},"8b666901-990a-420a-a9ed-996d5a88bd47":{"parent":"cee2ea15-d153-4954-94fc-f098fe536d5b","text":"Create new project folder","description":{"ops":[{"insert":"Create new project folder and navigate into it.\n"}]},"hist":[{"username":"admin","ds":"2023-10-15T18:31:20.740Z","fromId":"ed3d11e5-b716-44d3-965f-17d0e79a37b2"}],"variables":{"name":{"private":false,"ask":false,"type":"Text","value":"myProject","idn":"0"}},"script":"mkdir ~/{{c.name}}\ncd ~/{{c.name}}\n","sort":0,"id":"8b666901-990a-420a-a9ed-996d5a88bd47","type":"code"},"fb39eda8-86d7-455f-957f-3836dc9d5933":{"text":"Cloud","parent":"#","script":"","description":{"ops":[{"insert":"Cloud computing is the on-demand availability of computer system resources, especially data storage (cloud storage) and computing power, without direct active management by the user. Large clouds often have functions distributed over multiple locations, each of which is a data center. Cloud computing relies on sharing of resources to achieve coherence and typically uses a pay-as-you-go model, which can help in reducing capital expenses but may also lead to unexpected operating expenses for users.\n"},{"attributes":{"link":"https://en.wikipedia.org/wiki/Cloud_computing"},"insert":"https://en.wikipedia.org/wiki/Cloud_computing"},{"insert":"\n"}]},"id":"fb39eda8-86d7-455f-957f-3836dc9d5933","type":"code","variables":{},"sort":0},"9cee7e0d-1a7d-4c6a-8e08-c75f27f65e1b":{"parent":"fb39eda8-86d7-455f-957f-3836dc9d5933","text":"Openstack","description":{"ops":[{"attributes":{"link":"https://www.openstack.org/"},"insert":"https://www.openstack.org/"},{"insert":"\n"},{"attributes":{"bold":true},"insert":"The Most Widely Deployed Open Source Cloud Software in the World"},{"attributes":{"header":2},"insert":"\n"},{"insert":"Deployed by thousands. Proven production at scale. OpenStack is a set of software components that provide common services for cloud infrastructure.\n\n"},{"attributes":{"bold":true},"insert":"WHAT IS OPENSTACK?"},{"attributes":{"header":3},"insert":"\n"},{"insert":"OpenStack is a cloud operating system that controls large pools of compute, storage, and networking resources throughout a datacenter, all managed and provisioned through APIs with common authentication mechanisms.\nA dashboard is also available, giving administrators control while empowering their users to provision resources through a web interface.\nBeyond standard infrastructure-as-a-service functionality, additional components provide orchestration, fault management and service management amongst other services to ensure high availability of user applications.\n"}]},"hist":[{"username":"admin","ds":"2023-10-16T19:57:15.432Z","fromId":"12b9b55c-8083-4733-9563-f416e9f981a6"}],"variables":{},"script":"","sort":0,"id":"9cee7e0d-1a7d-4c6a-8e08-c75f27f65e1b","type":"code"},"da930003-2d5d-4929-84f3-e678602a706c":{"parent":"9cee7e0d-1a7d-4c6a-8e08-c75f27f65e1b","text":"Install Openstack Client","description":{"ops":[{"attributes":{"bold":true},"insert":"Installs openstackclient"},{"insert":"\n\nOpenStackClient (aka OSC) is a command-line client for OpenStack that brings the command set for Compute, Identity, Image, Network, Object Store and Block Storage APIs together in a single shell with a uniform command structure.\nThe primary goal is to provide a unified shell command structure and a common language to describe operations in OpenStack.\n"}]},"hist":[{"username":"admin","ds":"2023-10-16T19:57:15.432Z","fromId":"9e80bab9-50c1-44e6-bcec-f1d78ef80f1a"}],"variables":{},"script":"sudo apt -y install python3-openstackclient","id":"da930003-2d5d-4929-84f3-e678602a706c","type":"code","sort":0},"37eea0e0-856e-465e-9cbd-e575e8309c56":{"text":"Install openrc credentials file","parent":"9cee7e0d-1a7d-4c6a-8e08-c75f27f65e1b","script":"\ncd ~\n#Enter RAC project name\necho \"Enter RAC project name\"; read projectname\n\n#Enter RAC User name\necho \"Enter RAC user name\"; read username\n\nunset p\n\nprompt=\"Enter Password : \"\nwhile IFS= read -p \"$prompt\" -r -s -n 1 char\n-do\n-    if [[ $char == $'\\0' ]]\n-    then\n-        break\n-    fi\n-    prompt='*'\n-    p+=\"$char\"\n-done\n\n\n\nopenrc=\"\n-export OS_AUTH_URL=\\\"https://keystone-{{c.cloud}}.cloud.cybera.ca:5000/v3\\\" \\n\n-export OS_PROJECT_NAME=$projectname    \\n\n-export OS_USER_DOMAIN_NAME=Default     \\n\n-export OS_USERNAME=$username           \\n\n-export OS_PASSWORD=$p                  \\n\n-export OS_REGION_NAME=\\\"{{c.region}}\\\" \\n\n-export OS_IDENTITY_API_VERSION=3       \\n\n-\"\n\nif [ -z \"$projectname\" ] || [ -z \"$username\" ] || [ -z \"$p\" ] \n-then\n-      echo \"Empty input. Aborted.\"\n-else\n-      echo -e $openrc > openrc\n-      echo \"openrc written\"      \n-fi\n\n","description":{"ops":[{"insert":"To increase efficiency of client operations, OpenStack supports simple client environment scripts also known as OpenRC files. These scripts typically contain common options for all clients, but also support unique options. For more information, see the OpenStack End User Guide.\n"},{"attributes":{"link":"https://docs.openstack.org/newton/install-guide-rdo/keystone-openrc.html"},"insert":"https://docs.openstack.org/newton/install-guide-rdo/keystone-openrc.html"},{"insert":"\n\ncloud = yyc or yeg\nregion = Calgary or Edmonton\n\nEnter project name (usually your email), username (usually your email) and password (same as RAC) in the console when prompted.\n"}]},"sort":1,"id":"37eea0e0-856e-465e-9cbd-e575e8309c56","type":"code","variables":{"cloud":{"private":false,"ask":false,"type":"Text","value":"yyc","idn":"0"},"region":{"private":false,"ask":false,"type":"Text","value":"Calgary","idn":"1"}}},"04048382-39ff-4359-9af7-eed35e8a902e":{"text":"User Management","parent":"9cee7e0d-1a7d-4c6a-8e08-c75f27f65e1b","script":"","description":{"ops":[{"insert":"\n"}]},"sort":3,"id":"04048382-39ff-4359-9af7-eed35e8a902e","type":"code","variables":{}},"c8ffa51c-74e4-4dec-8878-6fd352952816":{"text":"User Show","parent":"04048382-39ff-4359-9af7-eed35e8a902e","script":"\ncd ~\n. openrc\nuser={{c.id}}\nret=$(openstack user show $user -f json)\n\necho \"var:userShow:$ret\"\n\nret=$(openstack project list --user $user -f json)\n\necho \"var:userProjectList:$ret\"","description":{"ops":[{"insert":"\n"}]},"sort":1,"id":"c8ffa51c-74e4-4dec-8878-6fd352952816","type":"code","variables":{"id":{"private":false,"ask":false,"type":"Text","value":"scott.hurd@cybera.ca","idn":"0"},"projShowID":{"private":false,"ask":false,"type":"Text","value":"10edee96-a3b3-4ffd-9531-d37f90a57900"}}},"14b69c72-028e-4b4b-988e-d512e1e89856":{"parent":"04048382-39ff-4359-9af7-eed35e8a902e","text":"User List","description":{"ops":[{"insert":"\n"}]},"hist":[{"ds":"2023-10-23T21:34:20.663Z","fromId":"c8ffa51c-74e4-4dec-8878-6fd352952816"},{"ds":"2024-01-02T20:58:59.997Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:42:34.750Z","event":"save","userName":"scott"},{"ds":"2024-01-03T19:09:04.511Z","event":"save","userName":"scott"}],"variables":{"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"0"},"icon":{"private":false,"ask":false,"type":"Text","value":"users","idn":"1"},"onclickJob":{"private":false,"ask":false,"type":"Text","value":"\nc8ffa51c-74e4-4dec-8878-6fd352952816","idn":"2"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"User List","idn":"3"}},"script":"\ncd ~\n# . openrc\n# ret=$(openstack user list --long -f json)\n\nsql=\"select JSON_ARRAYAGG(JSON_OBJECT('ID', user.id, 'Name', local_user.name , 'Enabled', enabled, 'Created_at', DATE_FORMAT(created_at,'%Y-%m-%d') )) from keystone.user INNER JOIN local_user ON user.id=local_user.user_id ORDER BY created_at DESC ;\"\n# Execute the sql and then chop off first line and then prettify the json with python \nret=$(mysql -h cloud.cybera.ca keystone -e \"$sql\" | sed 1d | python -m json.tool)\n\necho \"var:userList:$ret\"","sort":0,"id":"14b69c72-028e-4b4b-988e-d512e1e89856","type":"code"},"c29db03d-fb72-4795-9cfb-be11538578d5":{"parent":"9cee7e0d-1a7d-4c6a-8e08-c75f27f65e1b","text":"Project Management","description":{"ops":[{"insert":"\n"}]},"hist":[{"ds":"2023-10-28T21:50:03.282Z","fromId":"04048382-39ff-4359-9af7-eed35e8a902e"}],"variables":{},"script":"","sort":4,"id":"c29db03d-fb72-4795-9cfb-be11538578d5","type":"code"},"934754a3-db89-4683-a5bf-534b3d3c7ffa":{"parent":"c29db03d-fb72-4795-9cfb-be11538578d5","text":"Project List","description":{"ops":[{"insert":"\n"}]},"hist":[{"ds":"2023-10-28T21:51:30.184Z","fromId":"14b69c72-028e-4b4b-988e-d512e1e89856"}],"variables":{"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"0"},"icon":{"private":false,"ask":false,"type":"Text","value":"briefcase","idn":"1"},"onclickJob":{"private":false,"ask":false,"type":"Text","value":"10edee96-a3b3-4ffd-9531-d37f90a57900","idn":"2"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Projects","idn":"3"},"buttons":{"private":false,"ask":false,"type":"Text","value":"plus;34ead474-b96b-4bf6-a2e8-ebe1bd491393","idn":"4"}},"script":"\ncd ~\n. openrc\nret=$(openstack project list -f json --long --sort id:desc)\n\necho \"var:projectList:$ret\"","sort":0,"id":"934754a3-db89-4683-a5bf-534b3d3c7ffa","type":"code"},"10edee96-a3b3-4ffd-9531-d37f90a57900":{"parent":"c29db03d-fb72-4795-9cfb-be11538578d5","text":"Project Show","description":{"ops":[{"insert":"\n"}]},"hist":[{"ds":"2023-10-29T14:26:06.041Z","fromId":"c8ffa51c-74e4-4dec-8878-6fd352952816"}],"variables":{"id":{"private":false,"ask":false,"type":"Text","value":"scott.hurd@cybera.ca","idn":"0"},"buttons":{"private":false,"ask":false,"type":"Text","value":"List Users;2f894b3c-a442-4d0b-aad8-29c42041eb2b\nAdd Users;3683cde1-3fbf-433d-9ca8-d95446bec94d;users\nList Servers;05144d13-4a7f-43ce-b8ea-08f5375c0ce0\nCreate Server;8bc83c28-75e7-48e7-856d-f52a82fcd596;name"}},"script":"\ncd ~\n. openrc\n\nproject={{c.id}}\nret=$(openstack project show $project -f json)\n\necho \"var:projectShow:$ret\"\n","sort":1,"id":"10edee96-a3b3-4ffd-9531-d37f90a57900","type":"code"},"34ead474-b96b-4bf6-a2e8-ebe1bd491393":{"parent":"c29db03d-fb72-4795-9cfb-be11538578d5","text":"Project Create","description":{"ops":[{"insert":"Creates a new project and adds cyberabot user\n"}]},"hist":[{"ds":"2023-11-13T18:51:55.928Z","fromId":"10edee96-a3b3-4ffd-9531-d37f90a57900"}],"variables":{"name":{"private":false,"ask":false,"type":"Text","value":"test-project3","idn":"0"},"description":{"private":false,"ask":false,"type":"Text","value":"A new test proj","idn":"1"},"email":{"private":false,"ask":false,"type":"Text","value":"testuser@cybera.ca","idn":"2"}},"script":"\ncd ~\n. openrc\n\nret=$(openstack project create --description '{{c.description}}' {{c.name}} --domain default --property email={{c.email}} 2>&1 )\n\necho \"var:createProj:$ret\"","sort":4,"id":"34ead474-b96b-4bf6-a2e8-ebe1bd491393","type":"code"},"d0be684c-3424-40cc-8bb5-6f4249d516e0":{"text":"Server Management","parent":"c29db03d-fb72-4795-9cfb-be11538578d5","script":"","description":{"ops":[{"insert":"\n"}]},"sort":5,"id":"d0be684c-3424-40cc-8bb5-6f4249d516e0","type":"code","variables":{}},"05144d13-4a7f-43ce-b8ea-08f5375c0ce0":{"parent":"d0be684c-3424-40cc-8bb5-6f4249d516e0","text":"Server List","description":{"ops":[{"insert":"\n"}]},"hist":[{"ds":"2023-11-14T16:39:31.996Z","fromId":"10edee96-a3b3-4ffd-9531-d37f90a57900"}],"variables":{"id":{"private":false,"ask":false,"type":"Text","value":"scott.hurd@cybera.ca","idn":"0"},"servshowid":{"private":false,"ask":false,"type":"Text","value":"3dfbf534-6872-45ef-8a12-d3cd088281a2","idn":"1"}},"script":"\ncd ~\n. openrc\nexport OS_AUTH_URL=\"https://keystone-yyc.cloud.cybera.ca:5000/v3\"\nexport OS_REGION_NAME=\"Calgary\"\nproject={{c.id}}\n\nretYYC=$(openstack server list --project $project -f json)\n\nexport OS_AUTH_URL=\"https://keystone-yeg.cloud.cybera.ca:5000/v3\"\nexport OS_REGION_NAME=\"Edmonton\"\n\nretYEG=$(openstack server list --project $project -f json)\n\necho \"var:projectServerList:[$retYYC, $retYEG]\"\n","sort":0,"id":"05144d13-4a7f-43ce-b8ea-08f5375c0ce0","type":"code"},"2f894b3c-a442-4d0b-aad8-29c42041eb2b":{"parent":"c29db03d-fb72-4795-9cfb-be11538578d5","text":"Project User List","description":{"ops":[{"insert":"Provides a list of project members.\n"}]},"hist":[{"ds":"2023-11-14T18:01:21.023Z","fromId":"10edee96-a3b3-4ffd-9531-d37f90a57900"}],"variables":{"id":{"private":false,"ask":false,"type":"Text","value":"scott.hurd@cybera.ca","idn":"0"},"userShowID":{"private":false,"ask":false,"type":"Text","value":"c8ffa51c-74e4-4dec-8878-6fd352952816","idn":"1"}},"script":"\ncd ~\n. openrc\n\nproject={{c.id}}\n\nretMembers=$(openstack user list --project $project -f json)\n\necho \"var:projectUserList:$retMembers\"","sort":3,"id":"2f894b3c-a442-4d0b-aad8-29c42041eb2b","type":"code"},"3683cde1-3fbf-433d-9ca8-d95446bec94d":{"parent":"c29db03d-fb72-4795-9cfb-be11538578d5","text":"Add Users","description":{"ops":[{"insert":"Add users to a project. Specify the id or name of the project to amend and a list of users to add. Seperate users with a new line.\n"}]},"hist":[{"ds":"2023-11-14T21:55:07.084Z","fromId":"05144d13-4a7f-43ce-b8ea-08f5375c0ce0"}],"variables":{"users":{"private":false,"ask":false,"type":"Text","value":"testuser1@cybera.ca\ntestuser4@cybera.ca","idn":"0"},"role":{"private":false,"ask":false,"type":"Text","value":"Member","idn":"1"},"id":{"private":false,"ask":false,"type":"Text","value":"test-project3","idn":"2"}},"script":"\ncd ~\n. openrc\n\nusers=({{c.users}})\n\nfor i in \"${users[@]}\"; do\n-echo \"Adding: $i\"\n-openstack role add --user $i --project {{c.id}} {{c.role}}\n-done\n\nretMembers=$(openstack user list --project {{c.id}} -f json)\n\necho \"var:projectUserList:$retMembers\"\n","sort":2,"id":"3683cde1-3fbf-433d-9ca8-d95446bec94d","type":"code"},"8bc83c28-75e7-48e7-856d-f52a82fcd596":{"parent":"d0be684c-3424-40cc-8bb5-6f4249d516e0","text":"Server Create","description":{"ops":[{"insert":"Will create a new server in a specified project. \nThis script requires the cyberabot_openrc file to exist.\nThe /home/ubuntu/.ssh/authorized_keys file from the server these commands are running on, will be copied to the new server.\nA security group will be created with SSH open to ::/0\nImage: 07e44329-eeb1-42bd-b131-1dd565bd6283 | Ubuntu 22.04\n"}]},"hist":[{"ds":"2023-11-15T22:35:41.624Z","fromId":"05144d13-4a7f-43ce-b8ea-08f5375c0ce0"}],"variables":{"OS_REGION_NAME":{"private":false,"ask":false,"type":"Text","value":"Calgary","idn":"0"},"cloud":{"private":false,"ask":false,"type":"Text","value":"yyc","idn":"1"},"image":{"private":false,"ask":false,"type":"Text","value":"07e44329-eeb1-42bd-b131-1dd565bd6283","idn":"2"},"id":{"private":false,"ask":false,"type":"Text","value":"test-project3","idn":"3"},"flavor":{"private":false,"ask":false,"type":"Text","value":"1","idn":"4"},"security-group":{"private":false,"ask":false,"type":"Text","value":"default","idn":"5"},"name":{"private":false,"ask":false,"type":"Text","value":"testServer123123","idn":"6"}},"script":"\ncd ~\n. openrc\n. cyberabot_openrc\nexport OS_AUTH_URL=\"https://keystone-{{c.cloud}}.cloud.cybera.ca:5000/v3\"\nexport OS_REGION_NAME=\"{{c.OS_REGION_NAME}}\"\nproject={{c.id}}\nprojectName=$(openstack project list | grep $project | awk '{print $4}')\nexport OS_PROJECT_NAME=$projectName\n# get security group id of the specified name in the specified project\nsgid=$(openstack security group list --project $project -f value | grep \"{{c.security-group}}\" | awk '{print $1;}')\n\nopenstack keypair create {{c.name}}-key > {{c.name}}-key.pem\n# echo $ret > {{c.name}}-key.pem\nchmod 600 {{c.name}}-key.pem\n\n# --file <dst-path=src-path>\nret=$(openstack server create --flavor {{c.flavor}} --image {{c.image}} --key-name {{c.name}}-key --security-group $sgid --file /home/ubuntu/.ssh/authorized_keys=/home/ubuntu/.ssh/authorized_keys {{c.name}} -f json 2>&1)\n#ret=$(openstack server create --flavor {{c.flavor}} --image {{c.image}} --key-name {{c.name}}-key --security-group $sgid {{c.name}} -f json 2>&1)\necho $ret\nret=$(openstack security group rule create --ingress --remote-ip ::/0 --project $project --dst-port 22 --protocol tcp --ethertype IPv6 $sgid -f json 2>&1)\necho $ret\n\n. openrc\n\nexport OS_AUTH_URL=\"https://keystone-yyc.cloud.cybera.ca:5000/v3\"\nexport OS_REGION_NAME=\"Calgary\"\nproject={{c.id}}\nret=$(openstack project show $project -f json)\n\necho \"var:projectShow:$ret\"\n\nretYYC=$(openstack server list --project $project -f json)\n\nexport OS_AUTH_URL=\"https://keystone-yeg.cloud.cybera.ca:5000/v3\"\nexport OS_REGION_NAME=\"Edmonton\"\n\nretYEG=$(openstack server list --project $project -f json)\n\necho \"var:projectServerList:[$retYYC, $retYEG]\"","sort":3,"id":"8bc83c28-75e7-48e7-856d-f52a82fcd596","type":"code"},"0f6aa422-cc43-49da-b973-4dba64206d51":{"parent":"9cee7e0d-1a7d-4c6a-8e08-c75f27f65e1b","text":"Install bot credentials file","description":{"ops":[{"insert":"Only installs username and pw\n\nEnter username and password in the console when prompted.\nrc file will be named <picked-user-name>_openrc.\n"}]},"hist":[{"ds":"2023-11-15T23:02:12.930Z","fromId":"37eea0e0-856e-465e-9cbd-e575e8309c56"}],"variables":{},"script":"\ncd ~\n#Enter RAC User name\necho \"Enter RAC user name\"; read username\n\nunset p\n\nprompt=\"Enter Password : \"\nwhile IFS= read -p \"$prompt\" -r -s -n 1 char\n-do\n-    if [[ $char == $'\\0' ]]\n-    then\n-        break\n-    fi\n-    prompt='*'\n-    p+=\"$char\"\n-done\n\n\n\nopenrc=\"\n-export OS_USERNAME=$username           \\n\n-export OS_PASSWORD=$p                  \\n\n-\"\n\nif [ -z \"$username\" ] || [ -z \"$p\" ] \n-then\n-      echo \"Empty input. Aborted.\"\n-else\n-      username+=\"_openrc\"\n-      echo -e $openrc > $username\n-      echo \"file written\"      \n-fi\n\n","sort":2,"id":"0f6aa422-cc43-49da-b973-4dba64206d51","type":"code"},"6ef744a4-61c5-4511-abee-bd2879c6b3c3":{"parent":"d0be684c-3424-40cc-8bb5-6f4249d516e0","text":"Flavor  List","description":{"ops":[{"insert":"Find a flavor ID that meets your needs. \nUsually 1, 2 or 3.\n"}]},"hist":[{"ds":"2023-11-16T00:25:53.209Z","fromId":"8bc83c28-75e7-48e7-856d-f52a82fcd596"}],"variables":{},"script":"\ncd ~\n. openrc\nopenstack flavor list","sort":2,"id":"6ef744a4-61c5-4511-abee-bd2879c6b3c3","type":"code"},"3dfbf534-6872-45ef-8a12-d3cd088281a2":{"parent":"d0be684c-3424-40cc-8bb5-6f4249d516e0","text":"Server Show","description":{"ops":[{"insert":"\n"}]},"hist":[{"ds":"2023-11-16T02:09:27.308Z","fromId":"05144d13-4a7f-43ce-b8ea-08f5375c0ce0"}],"variables":{"id":{"private":false,"ask":false,"type":"Text","value":"80a1abff-e437-40ca-9b87-98a404bff264","idn":"0"}},"script":"\ncd ~\n. openrc\nexport OS_AUTH_URL=\"https://keystone-yyc.cloud.cybera.ca:5000/v3\"\nexport OS_REGION_NAME=\"Calgary\"\nserver={{c.id}}\n\nretYYC=$(openstack server show $server -f json )\n\nexport OS_AUTH_URL=\"https://keystone-yeg.cloud.cybera.ca:5000/v3\"\nexport OS_REGION_NAME=\"Edmonton\"\n\nretYEG=$(openstack server show $server -f json )\n\necho \"var:json:$retYYC $retYEG\"\n# echo \"var:preformatted:$retYEG\"\n","sort":1,"id":"3dfbf534-6872-45ef-8a12-d3cd088281a2","type":"code"},"bd0bd101-24e8-495f-869f-1861617dd4eb":{"parent":"c29db03d-fb72-4795-9cfb-be11538578d5","text":"Key Management","description":{"ops":[{"insert":"\n"}]},"hist":[{"ds":"2023-11-16T17:37:42.982Z","fromId":"d0be684c-3424-40cc-8bb5-6f4249d516e0"}],"variables":{},"script":"","sort":6,"id":"bd0bd101-24e8-495f-869f-1861617dd4eb","type":"code"},"1fc834af-01d6-4f71-9f84-6dc7e92e5019":{"parent":"bd0bd101-24e8-495f-869f-1861617dd4eb","text":"Key Create","description":{"ops":[{"insert":"Will create a new key pair in a specified project using cyberabot auth.\nSet id to project name or ID\n\nA private key file will be generated. \n<name>-key.pem\n\n\n"}]},"hist":[{"ds":"2023-11-16T17:39:26.885Z","fromId":"8bc83c28-75e7-48e7-856d-f52a82fcd596"}],"variables":{"OS_REGION_NAME":{"private":false,"ask":false,"type":"Text","value":"Calgary","idn":"0"},"cloud":{"private":false,"ask":false,"type":"Text","value":"yyc","idn":"1"},"id":{"private":false,"ask":false,"type":"Text","value":"test-project3","idn":"3"},"name":{"private":false,"ask":false,"type":"Text","value":"testServer123123","idn":"6"}},"script":"\ncd ~\n. openrc\n. cyberabot_openrc\nexport OS_AUTH_URL=\"https://keystone-{{c.cloud}}.cloud.cybera.ca:5000/v3\"\nexport OS_REGION_NAME=\"{{c.OS_REGION_NAME}}\"\nproject={{c.id}}\nprojectName=$(openstack project list | grep $project | awk '{print $4}')\nexport OS_PROJECT_NAME=$projectName\n\nopenstack keypair create {{c.name}}-key > {{c.name}}-key.pem\n# echo $ret > {{c.name}}-key.pem\nchmod 600 {{c.name}}-key.pem\n","sort":0,"id":"1fc834af-01d6-4f71-9f84-6dc7e92e5019","type":"code"},"8bee2d57-a81a-4e96-883e-54576a2ff86e":{"text":"Shell","parent":"d0be684c-3424-40cc-8bb5-6f4249d516e0","script":"","description":{"ops":[{"insert":"\n"}]},"sort":9000,"id":"8bee2d57-a81a-4e96-883e-54576a2ff86e","type":"code","variables":{}},"8ced9b2a-ec8f-412b-860d-8a35b3108a90":{"text":"testtttt3334","parent":"8bee2d57-a81a-4e96-883e-54576a2ff86e","script":"\ncd ~\nssh ubuntu@{{c.ip}} -i {{c.pk}} \n-sleep 3; PS1=[ceStack]$PS1\n","description":{"ops":[{"insert":"This script will ssh into a specified address and add the prompt tag \"[ceStack]\".\nThis script assumes a linux env that changes the prompt via the PS1 variable.\n\nip = ipaddress\npk = private key file\n"}]},"sort":9000,"id":"8ced9b2a-ec8f-412b-860d-8a35b3108a90","type":"code","variables":{"ip":{"private":false,"ask":false,"type":"Text","value":"2605:fd00:4:1000:f816:3eff:fea8:fe51","idn":"0"},"pk":{"private":false,"ask":false,"type":"Text","value":"testtttt3334-key.pem","idn":"1"}},"found":true},"026ce1a5-d4ca-44f0-97ed-b12fc3fc3bad":{"parent":"ea841508-edb1-4fd7-aca1-46fbb21a97a3","text":"new Test 233","hist":[{"ds":"2023-11-17T19:23:38.669Z","fromId":"032aea7f-5e3d-44a6-a6ba-5269bdf246b5"}],"variables":{},"sort":0,"id":"026ce1a5-d4ca-44f0-97ed-b12fc3fc3bad","type":"code","script":"","description":{"ops":[{"insert":"\n"}]}},"1174210e-5ce6-44fc-939f-3b362b49f6a8":{"parent":"5d56ccbb-e6aa-4ab8-b51b-d97e3603b284","text":"DVC add Swift endpoint","description":{"ops":[{"insert":"This script will create and execute an RC file that will connect DVC to a swift endpoint.\nset remote_name to the name of the new endpoint.\nset swift-REGION-URL to the swift url for your environment.\nset containername to the name of your container in swift.\n\nThe name of the RC file is \"swiftRC\". \n"}]},"hist":[{"ds":"2023-11-27T19:00:30.617Z","fromId":"27a2991b-6d6c-42ca-9af6-34b242ce8562"}],"variables":{"remote_name":{"private":false,"ask":false,"type":"Text","value":"test","idn":"0"},"swift-REGION-URL":{"private":false,"ask":false,"type":"Text","value":"https://swift-yyc.cloud.cybera.ca:8080","idn":"1"},"containername":{"private":false,"ask":false,"type":"Text","value":"mycontainer","idn":"2"}},"script":"cd ~\n. openrc\n\nprojectID=$(openstack project list | grep \" $OS_PROJECT_NAME \" | awk '{print $2}')\n\n__rc_text=\"\n-export AWS_ACCESS_KEY_ID=\\$(openstack ec2 credentials list | grep {{c.projectID}} | awk '{print \\$2}') \n-export AWS_SECRET_ACCESS_KEY=\\$(openstack ec2 credentials show \\$AWS_ACCESS_KEY_ID -c secret -f value)\n-dvc remote add -d {{c.remote_name}} s3://{{c.containername}}\n-dvc remote modify {{c.remote_name}} endpointurl {{c.swift-REGION-URL}} \n-\"\n\necho \"$__rc_text\" > swiftRC\n. swiftRC\n","sort":1,"id":"1174210e-5ce6-44fc-939f-3b362b49f6a8","type":"code","found":true},"2b6382b2-b150-43a0-b5e1-314801fa911e":{"text":"Services","parent":"9cee7e0d-1a7d-4c6a-8e08-c75f27f65e1b","script":"","description":{"ops":[{"insert":"\n"}]},"sort":9000,"id":"2b6382b2-b150-43a0-b5e1-314801fa911e","type":"code","variables":{}},"436d8352-93aa-4959-a59a-16b715520377":{"text":"mysql","parent":"2b6382b2-b150-43a0-b5e1-314801fa911e","script":"","description":{"ops":[{"insert":"Most OpenStack services use an SQL database to store information. The database typically runs on the controller node. The procedures in this guide use MariaDB or MySQL depending on the distribution. OpenStack services also support other SQL databases including PostgreSQL.\n"}]},"sort":9000,"id":"436d8352-93aa-4959-a59a-16b715520377","type":"code","variables":{}},"9c4e49d2-81ba-40be-aaee-f408508cef87":{"text":"Show databases","parent":"436d8352-93aa-4959-a59a-16b715520377","script":"cd ~\n\nmysql -h cloud.cybera.ca -e \"show databases\"","description":{"ops":[{"insert":"This script will use the mysql cli to logon and show databases;\nThis script requires a mysqlrc to exist and the mysql cli client to be available.\n"}]},"sort":1,"id":"9c4e49d2-81ba-40be-aaee-f408508cef87","type":"code","variables":{}},"09dab7ef-96a3-4752-9f4a-4790db27d46a":{"parent":"436d8352-93aa-4959-a59a-16b715520377","text":"Install mysql credentials file","description":{"ops":[{"insert":"Both for MySQL and PostgreSQL you can specify your user and password in local config file. .my.cnf for MySQL and .pgpass for PostgreSQL. These files should be in your home directory (i.e. ~/.my.cnf).\n\nEnter your userid and password in the console when prompted.\n"}]},"hist":[{"ds":"2023-12-03T18:22:13.803Z","fromId":"37eea0e0-856e-465e-9cbd-e575e8309c56"}],"variables":{},"script":"\ncd ~\n#Enter mysql User name\necho \"Enter mysql user name\"; read username\n\nunset p\n\nprompt=\"Enter Password : \"\nwhile IFS= read -p \"$prompt\" -r -s -n 1 char\n-do\n-    if [[ $char == $'\\0' ]]\n-    then\n-        break\n-    fi\n-    prompt='*'\n-    p+=\"$char\"\n-done\n\nrc=\"\n-[mysql]\n-user=$username \n-password=$p \n-\"\n\nif [ -z \"$username\" ] || [ -z \"$p\" ] \n-then\n-      echo \"Empty input. Aborted.\"\n-else\n-      echo -e \"$rc\" > .my.cnf\n-      echo \".my.cnf written\"      \n-fi\n\n","sort":0,"id":"09dab7ef-96a3-4752-9f4a-4790db27d46a","type":"code"},"aabaa672-38c3-4834-a8fc-0a2d09a17508":{"text":"Export user db","parent":"436d8352-93aa-4959-a59a-16b715520377","script":"cd ~\n\nmysql -h cloud.cybera.ca keystone -e \"select JSON_OBJECT('id', id,'extra', extra, 'enabled', enabled) from user;\"  > test_data.json","description":{"ops":[{"insert":"\n"}]},"sort":9000,"id":"aabaa672-38c3-4834-a8fc-0a2d09a17508","type":"code","variables":{}},"a6d2cf6a-e20e-475a-b0cd-1a6585425f3c":{"text":"Reboot","parent":"b1e874e9-a642-4920-8624-355118328fb1","script":"\nsudo reboot","description":{"ops":[{"insert":"\n"}]},"sort":9000,"id":"a6d2cf6a-e20e-475a-b0cd-1a6585425f3c","type":"code","variables":{}},"a4f4c9a8-7f85-4808-9ff9-87ea6de0b1a9":{"text":"PostgreSQL","parent":"2b6382b2-b150-43a0-b5e1-314801fa911e","script":"","description":{"ops":[{"insert":"PostgreSQL is another database tech that Cybera uses to manage RAC.\n"}]},"sort":9000,"id":"a4f4c9a8-7f85-4808-9ff9-87ea6de0b1a9","type":"code","variables":{}},"2fe714f5-873c-4d76-8f61-71400a27feb2":{"parent":"a4f4c9a8-7f85-4808-9ff9-87ea6de0b1a9","text":"Install PostgreSQL credentials file","description":{"ops":[{"insert":"Both for MySQL and PostgreSQL you can specify your user and password in local config file. .my.cnf for MySQL and .pgpass for PostgreSQL. These files should be in your home directory (i.e. ~/.pgpass).\n\nEnter your userid and password in the console when prompted.\n"}]},"hist":[{"ds":"2023-12-09T17:16:41.062Z","fromId":"09dab7ef-96a3-4752-9f4a-4790db27d46a"}],"variables":{},"script":"\ncd ~\n\necho \"Enter PostgreSQL user name\"; read username\n\nunset p\n\nprompt=\"Enter Password : \"\nwhile IFS= read -p \"$prompt\" -r -s -n 1 char\n-do\n-    if [[ $char == $'\\0' ]]\n-    then\n-        break\n-    fi\n-    prompt='*'\n-    p+=\"$char\"\n-done\n\nrc=\"*:*:*:$username:$p\"\n\nif [ -z \"$username\" ] || [ -z \"$p\" ] \n-then\n-      echo \"Empty input. Aborted.\"\n-else\n-      echo -e \"$rc\" > .pgpass\n-      chmod 0600 .pgpass\n-      echo \".pgpass written\"      \n-fi\n\n","sort":0,"id":"2fe714f5-873c-4d76-8f61-71400a27feb2","type":"code"},"4eafd576-5cc7-470a-92f4-b5e1b5aa4550":{"text":"Install PostgreSQL","parent":"a4f4c9a8-7f85-4808-9ff9-87ea6de0b1a9","script":"# sudo apt install -y postgresql-client-common\n# sudo apt-get install postgresql-client\n# psql -h rac-portal.cybera.ca -u rac -d rac -c \"select * from users\" \n\nsudo apt install -y postgresql postgresql-contrib","description":{"ops":[{"insert":"\n"}]},"sort":9000,"id":"4eafd576-5cc7-470a-92f4-b5e1b5aa4550","type":"code","variables":{}},"a0330258-7f53-48b8-8f82-23a4c667e5e1":{"text":"Volumes","parent":"2b6382b2-b150-43a0-b5e1-314801fa911e","script":"","description":{"ops":[{"insert":"\n"}]},"sort":9000,"id":"a0330258-7f53-48b8-8f82-23a4c667e5e1","type":"code","variables":{}},"199a1041-ba88-49b7-a6cf-6181d72aec0f":{"parent":"a0330258-7f53-48b8-8f82-23a4c667e5e1","text":"Volume Show","description":{"ops":[{"insert":"\n"}]},"hist":[{"ds":"2023-12-11T19:53:23.105Z","fromId":"3dfbf534-6872-45ef-8a12-d3cd088281a2"}],"variables":{"id":{"private":false,"ask":false,"type":"Text","value":"3dfb64e9-77ab-44a3-a1d4-be1ced6a04a8","idn":"0"}},"script":"\ncd ~\n. openrc\nexport OS_AUTH_URL=\"https://keystone-yyc.cloud.cybera.ca:5000/v3\"\nexport OS_REGION_NAME=\"Calgary\"\nvol={{c.id}}\n\nretYYC=$(openstack volume show $vol -f json )\n\nexport OS_AUTH_URL=\"https://keystone-yeg.cloud.cybera.ca:5000/v3\"\nexport OS_REGION_NAME=\"Edmonton\"\n\nretYEG=$(openstack volume show $vol -f json )\n\necho \"var:json:$retYYC $retYEG\"\n# echo \"var:preformatted:$retYEG\"\n","sort":0,"id":"199a1041-ba88-49b7-a6cf-6181d72aec0f","type":"code"},"ae63bbf9-1ebd-40e2-a001-bc1b4c772564":{"text":"DS Environment","parent":"#","script":"","description":{"ops":[{"insert":"This component contains Data Science Environments. \n"}]},"sort":9000,"id":"ae63bbf9-1ebd-40e2-a001-bc1b4c772564","type":"code","variables":{},"hist":[{"ds":"2023-12-21T18:39:36.090Z","event":"save","userName":"scott"}]},"6e8a583f-131d-4ae9-8fd5-891027eebb4b":{"text":"DS v01","parent":"ae63bbf9-1ebd-40e2-a001-bc1b4c772564","script":"","description":{"ops":[{"insert":"Alpha build of Data Science compute environment\n"}]},"sort":9000,"id":"6e8a583f-131d-4ae9-8fd5-891027eebb4b","type":"code","variables":{}},"b84e6b65-6fe9-4a00-8c51-2bad7eaf30c1":{"text":"Docker Streamlit","parent":"6e8a583f-131d-4ae9-8fd5-891027eebb4b","script":"\n\necho '\n-{{c.dockerFile}}\n-' > Dockerfile\n\ndocker build -t {{c.imageName}} --build-arg REPO={{c.repo}} .\n\ndocker run -d -p {{c.port}}:{{c.port}} {{c.imageName}} {{c.containername}}\n\nip6=$( ip a | grep inet6 | cut -d \" \" --fields=6 | sed '2q;d' | awk -F'/' '{print $1}' )\n\nurlR=$(dig -x $ip6 | grep rac | awk {' print $5 '})\nurl=${urlR::-1}:{{c.port}}\n\necho \"var:url:http://$url\"\n\necho \"var:url:http://[$ip6]\":{{c.port}}\n\n\n\n\n\n","description":{"ops":[{"insert":"\n"}]},"sort":9000,"id":"b84e6b65-6fe9-4a00-8c51-2bad7eaf30c1","type":"code","variables":{"repo":{"private":false,"ask":false,"type":"Text","value":"https://github.com/streamlit/streamlit-example.git","idn":"0"},"containername":{"private":false,"ask":false,"type":"Text","value":"mytest","idn":"1"},"dockerFile":{"private":false,"ask":false,"type":"Text","value":"# app/Dockerfile\nFROM ubuntu:latest\nARG REPO\nARG TOKEN\nWORKDIR /app\nRUN apt-get update && apt-get install -y \\\n    build-essential \\\n    curl \\\n    software-properties-common \\\n    git \\\n    python3-pip \\\n    && rm -rf /var/lib/apt/lists/*\nRUN git clone $REPO .\nRUN pip3 install -r requirements.txt\nEXPOSE 8501\nHEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health\nENTRYPOINT [\"streamlit\", \"run\", \"streamlit_app.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"]","idn":"2"},"imageName":{"private":false,"ask":false,"type":"Text","value":"streamlit","idn":"3"},"port":{"private":false,"ask":false,"type":"Text","value":"8501","idn":"4"}},"hist":[{"ds":"2023-12-21T19:22:04.751Z","event":"save","userName":"scott"},{"ds":"2023-12-21T19:23:11.007Z","event":"save","userName":"scott"},{"ds":"2023-12-21T19:26:53.650Z","event":"save","userName":"scott"}]},"ef165b80-a1ba-4657-828e-09f46b0d9478":{"parent":"37eea0e0-856e-465e-9cbd-e575e8309c56","text":"Install region rc file","description":{"ops":[{"insert":"Install a rc file that will allow you to switch regions easily.\n\ncloud = yyc or yeg\nregion = Calgary or Edmonton\n\nThe rc file name will be <cloud>rc.\n"}]},"hist":[{"ds":"2023-12-12T20:49:02.937Z","fromId":"37eea0e0-856e-465e-9cbd-e575e8309c56"}],"variables":{"cloud":{"private":false,"ask":false,"type":"Text","value":"yeg"},"region":{"private":false,"ask":false,"type":"Text","value":"Edmonton"}},"script":"\ncd ~\n\nrc=\"\n-export OS_AUTH_URL=\\\"https://keystone-{{c.cloud}}.cloud.cybera.ca:5000/v3\\\" \n-export OS_REGION_NAME=\\\"{{c.region}}\\\" \n-\"\n\necho -e \"$rc\" > {{c.cloud}}rc\necho \"openrc written\"      \n\n\n","sort":0,"id":"ef165b80-a1ba-4657-828e-09f46b0d9478","type":"code"},"f3f19cc0-8b7c-4507-8f70-aae6fd6e77dd":{"text":"Storage","parent":"6e8a583f-131d-4ae9-8fd5-891027eebb4b","script":"","description":{"ops":[{"insert":"Technologies to assist in storage.\n"}]},"sort":9000,"id":"f3f19cc0-8b7c-4507-8f70-aae6fd6e77dd","type":"code","variables":{},"hist":[{"ds":"2023-12-21T20:22:13.348Z","event":"save","userName":"scott"}]},"44e0c854-ac81-42c2-9368-7c4cb1e42934":{"text":"Openstack Swift","parent":"f3f19cc0-8b7c-4507-8f70-aae6fd6e77dd","script":"#Containers\nopenstack container --help\n#objects\nopenstack object --help","description":{"ops":[{"insert":"Swift is a highly available, distributed, eventually consistent object/blob store. Organizations can use Swift to store lots of data efficiently, safely, and cheaply.\n\n"}]},"sort":9000,"hist":[{"ds":"2023-12-21T18:46:53.918Z","event":"new","userName":"scott"},{"ds":"2023-12-21T18:47:17.224Z","event":"save","userName":"scott"},{"ds":"2023-12-21T18:48:09.213Z","event":"save","userName":"scott"},{"ds":"2023-12-21T18:48:53.693Z","event":"save","userName":"scott"},{"ds":"2023-12-21T18:51:37.407Z","event":"save","userName":"scott"},{"ds":"2023-12-21T18:57:18.466Z","event":"save","userName":"scott"}],"id":"44e0c854-ac81-42c2-9368-7c4cb1e42934","type":"code","variables":{}},"e87a23b5-0c1b-4313-b58d-888b9d536f7c":{"text":"Container create","parent":"44e0c854-ac81-42c2-9368-7c4cb1e42934","script":"\n. openrc\n\nopenstack container create {{c.container-name}}\n\n","description":{"ops":[{"insert":"This will create a new object storage container on your RAC project.\n"}]},"sort":0,"hist":[{"ds":"2023-12-21T18:51:41.903Z","event":"new","userName":"scott"},{"ds":"2023-12-21T18:55:13.033Z","event":"save","userName":"scott"},{"ds":"2023-12-21T18:55:25.688Z","event":"save","userName":"scott"},{"ds":"2023-12-21T18:58:17.754Z","event":"save","userName":"scott"}],"id":"e87a23b5-0c1b-4313-b58d-888b9d536f7c","type":"code","variables":{"container-name":{"private":false,"ask":false,"type":"Text","value":"myContainer","idn":"0"}}},"70c75903-2d0e-4692-8f1b-11d9e0be9fb5":{"text":"List containers","parent":"44e0c854-ac81-42c2-9368-7c4cb1e42934","script":"\n. openrc\n\nopenstack container list\n\n","description":{"ops":[{"insert":"List containers\n"}]},"sort":1,"hist":[{"ds":"2023-12-21T19:01:23.339Z","event":"new","userName":"scott"},{"ds":"2023-12-21T19:03:05.227Z","event":"save","userName":"scott"}],"id":"70c75903-2d0e-4692-8f1b-11d9e0be9fb5","type":"code","variables":{}},"44a623fb-ff11-4cb4-ad86-4cb2391b5ab7":{"text":"Object List","parent":"44e0c854-ac81-42c2-9368-7c4cb1e42934","script":"\n. openrc\n\nopenstack object list {{c.container}}\n\n","description":{"ops":[{"insert":"List objects in a container\n"}]},"sort":2,"hist":[{"ds":"2023-12-21T19:06:21.011Z","event":"new","userName":"scott"},{"ds":"2023-12-21T19:11:15.584Z","event":"save","userName":"scott"},{"ds":"2023-12-21T19:14:18.285Z","event":"save","userName":"scott"}],"id":"44a623fb-ff11-4cb4-ad86-4cb2391b5ab7","type":"code","variables":{"container":{"private":false,"ask":false,"type":"Text","value":"myContainer","idn":"1"}}},"7bb8192e-a812-4623-b6f0-24bbf1c3186d":{"parent":"b84e6b65-6fe9-4a00-8c51-2bad7eaf30c1","text":"Show running Docker containers","description":{"ops":[{"insert":"Show a list of all Docker containers\n"}]},"hist":[{"ds":"2023-12-21T19:41:26.908Z","fromId":"761c1cbe-2505-493c-8221-87e2e5ed960a","userName":"scott"},{"ds":"2023-12-21T19:41:48.239Z","event":"save","userName":"scott"}],"variables":{},"script":"docker ps -a","sort":0,"id":"7bb8192e-a812-4623-b6f0-24bbf1c3186d","type":"code"},"706baae8-6939-4ad9-a0f8-95bc5894b5e1":{"parent":"b84e6b65-6fe9-4a00-8c51-2bad7eaf30c1","text":"Stop Docker container","description":{"ops":[{"insert":"Stops a running container. Specify ID or name.\n\nTo stop all running docker containers use: docker stop $(docker ps -a -q)\n\n"}]},"hist":[{"ds":"2023-12-21T19:43:03.599Z","fromId":"33e53857-3391-4d4f-b3d4-5be9389e2bd6","userName":"scott"},{"ds":"2023-12-21T19:43:13.142Z","event":"save","userName":"scott"},{"ds":"2023-12-21T19:51:45.932Z","event":"save","userName":"scott"},{"ds":"2023-12-22T16:02:32.750Z","event":"save","userName":"scott"}],"variables":{"container":{"private":false,"ask":false,"type":"Text","value":"happy_lovelace"}},"script":"docker stop {{c.container}}","sort":1,"id":"706baae8-6939-4ad9-a0f8-95bc5894b5e1","type":"code"},"8825920f-514f-4aa9-9a69-0789db6e3e17":{"parent":"44e0c854-ac81-42c2-9368-7c4cb1e42934","text":"ec2 Credentials List","description":{"ops":[{"insert":"Get your ec2 Access Code and Secret key \n"}]},"hist":[{"ds":"2023-12-29T17:59:11.268Z","fromId":"44a623fb-ff11-4cb4-ad86-4cb2391b5ab7","userName":"scott"},{"ds":"2023-12-29T18:02:02.305Z","event":"save","userName":"scott"}],"variables":{},"script":"\n. openrc\n\nopenstack ec2 credentials list\n","sort":3,"id":"8825920f-514f-4aa9-9a69-0789db6e3e17","type":"code"},"e13a86ff-5c45-4b08-a734-96d672cdd1f7":{"text":"Volume Users Report","parent":"a0330258-7f53-48b8-8f82-23a4c667e5e1","script":"\n\nsql=\"SELECT DISTINCT keystone.user.extra->>'$.email' from cinder_{{c.region}}.volumes INNER JOIN keystone.user WHERE cinder_{{c.region}}.volumes.host LIKE '%{{c.host}}%' AND keystone.user.id = cinder_{{c.region}}.volumes.user_id AND cinder_{{c.region}}.volumes.attach_status = 'attached' AND keystone.user.enabled = '1';\"\n\n# Execute the sql and then chop off first line \nret=$(mysql -h cloud.cybera.ca cinder_yyc -e \"$sql\" | sed 1d)\n\necho \"var:preformatted: List all enabled users who have an attached volume on {{c.host}}.\n-$ret\"\n\n","description":{"ops":[{"insert":"List all enabled users who have an attached volume on a specified server.\n"}]},"sort":9000,"hist":[{"ds":"2024-01-02T20:54:36.332Z","event":"new","userName":"scott"},{"ds":"2024-01-02T20:57:50.437Z","event":"save","userName":"scott"},{"ds":"2024-01-02T20:59:32.957Z","event":"save","userName":"scott"},{"ds":"2024-01-02T21:01:08.713Z","event":"save","userName":"scott"},{"ds":"2024-01-02T21:01:44.200Z","event":"save","userName":"scott"},{"ds":"2024-01-02T21:03:56.500Z","event":"save","userName":"scott"},{"ds":"2024-01-02T21:13:29.478Z","event":"save","userName":"scott"},{"ds":"2024-01-02T21:28:11.883Z","event":"save","userName":"scott"},{"ds":"2024-01-02T21:29:08.103Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:06:47.567Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:16:16.256Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:20:15.928Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:21:38.548Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:28:46.493Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:29:35.458Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:30:29.826Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:32:14.174Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:35:24.461Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:39:02.983Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:40:35.329Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:45:57.652Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:48:48.939Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:49:20.359Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:52:39.989Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:54:06.565Z","event":"save","userName":"scott"},{"ds":"2024-01-03T18:54:16.533Z","event":"save","userName":"scott"},{"ds":"2024-01-03T19:11:42.043Z","event":"save","userName":"scott"},{"ds":"2024-01-03T19:13:22.054Z","event":"save","userName":"scott"},{"ds":"2024-01-03T19:14:40.509Z","event":"save","userName":"scott"},{"ds":"2024-01-03T19:16:21.100Z","event":"save","userName":"scott"},{"ds":"2024-01-03T19:17:02.581Z","event":"save","userName":"scott"},{"ds":"2024-01-03T19:17:36.895Z","event":"save","userName":"scott"}],"id":"e13a86ff-5c45-4b08-a734-96d672cdd1f7","type":"code","variables":{"host":{"private":false,"ask":true,"type":"Text","value":"yeg-v03","idn":"0"},"region":{"private":false,"ask":true,"type":"Text","value":"yeg","idn":"1"},"promoted":{"private":false,"ask":false,"type":"Text","value":"true","idn":"2"},"icon":{"private":false,"ask":false,"type":"Text","value":"database","idn":"3"},"listTitle":{"private":false,"ask":false,"type":"Text","value":"Volume user report","idn":"4"}}}}